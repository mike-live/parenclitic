{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "#from load_data_mongoloids import load_data_mongoloids\n",
    "#from mongoloids_config import config\n",
    "\n",
    "#from load_data_cancer import load_data_cancer\n",
    "#from cancer_config import config\n",
    "import re\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "#import plotly.plotly as py\n",
    "import textwrap\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from scipy import stats\n",
    "from sklearn import neighbors, ensemble, linear_model, neural_network\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "\n",
    "from infrastructure.configuration import param\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn\n",
    "seaborn.set_style('darkgrid', {'legend.frameon':True})\n",
    "fontsize = 20\n",
    "params = {'legend.fontsize': fontsize,\n",
    "  'figure.figsize': (18, 15),\n",
    "  'axes.labelsize': fontsize,\n",
    "  'axes.titlesize':fontsize,\n",
    "  'xtick.labelsize':fontsize,\n",
    "  'ytick.labelsize':fontsize,\n",
    "  'font.size':fontsize}\n",
    "pylab.rcParams.update(params)\n",
    "plt.rc('axes', labelsize=fontsize) \n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "import igraph\n",
    "import cairo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_parenclitics import load_parenclitics\n",
    "from transform_data import parenclitic_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\PC\\UNN\\Science\\Gerontology\\data\\random_graph\\params\\num_genes_14756\\parenclitics\\parenclitic.mat\n"
     ]
    }
   ],
   "source": [
    "#from configurations.config_random_graph import config\n",
    "#parenclitics_rg = load_parenclitics(config, by_sample = True, id_thr = 5, from_mat = True)\n",
    "\n",
    "from configurations.config_random_graph import config\n",
    "parenclitics_rg = load_parenclitics(config, by_sample = True, id_thr = 5, from_mat = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\PC\\UNN\\Science\\Gerontology\\data\\GSE52588\\GSE52588_average_beta.txt\n",
      "Data loaded:  1.2071621000000006\n",
      "float32 (14756, 87)\n",
      "(87, 14756) 14756\n"
     ]
    }
   ],
   "source": [
    "from configurations.load_data_down_GSE52588 import load_data_down_GSE52588\n",
    "from configurations.config_down_GSE52588 import config\n",
    "\n",
    "X, y, mask, genes_names = load_data_down_GSE52588()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded:  50.8244918\n",
      "float32 (422801, 87)\n",
      "(87, 114674)\n",
      "(87, 114674) 114674 (87,) (114674,)\n"
     ]
    }
   ],
   "source": [
    "from configurations.load_data_down_GSE52588 import load_data_down_GSE52588_cpgs\n",
    "from configurations.config_down_GSE52588_cpg import config\n",
    "\n",
    "X, y, mask, genes_names = load_data_down_GSE52588_cpgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\PC\\UNN\\Science\\Gerontology\\data\\GSE52588\\params\\num_cpgs_114674\\kde_mask_nonhealthy_mask\\algorithm_pdf\\thr_type_best\\division_rule_non_control\\parenclitics\\parenclitic.mat\n"
     ]
    }
   ],
   "source": [
    "from load_parenclitics import load_parenclitics\n",
    "from transform_data import parenclitic_feature_names\n",
    "parenclitics = load_parenclitics(config, by_sample = True, id_thr = 5, from_mat = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\PC\\UNN\\Science\\Gerontology\\data\\GSE52588\\params\\num_genes_14756\\kde_mask_mothers_mask\\algorithm_svc\\parenclitics\\parenclitic.mat\n",
      "(87, 45)\n",
      "D:\\PC\\UNN\\Science\\Gerontology\\data\\GSE52588\\params\\num_genes_14756\\kde_mask_siblings_mask\\algorithm_svc\\parenclitics\\parenclitic.mat\n",
      "(87, 45)\n",
      "D:\\PC\\UNN\\Science\\Gerontology\\data\\GSE52588\\params\\num_genes_14756\\kde_mask_mongoloids_mask\\algorithm_svc\\parenclitics\\parenclitic.mat\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\PC\\\\UNN\\\\Science\\\\Gerontology\\\\data\\\\GSE52588\\\\params\\\\num_genes_14756\\\\kde_mask_mongoloids_mask\\\\algorithm_svc\\\\parenclitics\\\\parenclitic.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\PC\\\\UNN\\\\Science\\\\Gerontology\\\\data\\\\GSE52588\\\\params\\\\num_genes_14756\\\\kde_mask_mongoloids_mask\\\\algorithm_svc\\\\parenclitics\\\\parenclitic.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f0d41a52c863>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"kde_mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"mongoloids_mask\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"kde_mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mcur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_parenclitics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_thr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mparenclitics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\PC\\UNN\\Science\\Gerontology\\programs\\parenclitic\\src\\load_parenclitics.py\u001b[0m in \u001b[0;36mload_parenclitics\u001b[1;34m(config, by_sample, id_thr, from_mat)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mofname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"parenclitic\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\".mat\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"parenclitic\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mparenclitics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'parenclitics'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mparenclitic_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'parenclitic_features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \"\"\"\n\u001b[0;32m    140\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variable_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[0mMR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m     \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[1;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \"\"\"\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mbyte_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0mmjv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_matfile_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'.mat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\PC\\\\UNN\\\\Science\\\\Gerontology\\\\data\\\\GSE52588\\\\params\\\\num_genes_14756\\\\kde_mask_mongoloids_mask\\\\algorithm_svc\\\\parenclitics\\\\parenclitic.mat'"
     ]
    }
   ],
   "source": [
    "from load_parenclitics import load_parenclitics\n",
    "from transform_data import parenclitic_feature_names\n",
    "\n",
    "config.params[\"kde_mask\"].value = \"mothers_mask\"\n",
    "mask = config.params[config.params[\"kde_mask\"].value].value\n",
    "parenclitics = load_parenclitics(config, by_sample = True, id_thr = 5, from_mat = True)\n",
    "print(parenclitics.shape)\n",
    "\n",
    "config.params[\"kde_mask\"].value = \"siblings_mask\"\n",
    "mask = config.params[config.params[\"kde_mask\"].value].value\n",
    "cur = load_parenclitics(config, by_sample = True, id_thr = 5, from_mat = True)\n",
    "print(cur.shape)\n",
    "parenclitics.iloc[mask] = cur.loc[mask]\n",
    "\n",
    "config.params[\"kde_mask\"].value = \"mongoloids_mask\"\n",
    "mask = config.params[config.params[\"kde_mask\"].value].value\n",
    "cur = load_parenclitics(config, by_sample = True, id_thr = 5, from_mat = True)\n",
    "print(cur.shape)\n",
    "parenclitics.iloc[mask] = cur.loc[mask]\n",
    "\n",
    "print(parenclitics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 45)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    parenclitics_rg\n",
    "except:\n",
    "    parenclitics_rg = None\n",
    "    \n",
    "if not parenclitics_rg is None:\n",
    "    cur = parenclitics_rg.loc[0:28] # ShiT! This indexing give closed range 0..28\n",
    "    parenclitics = parenclitics.append(cur, ignore_index = True, sort=False)\n",
    "print(parenclitics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['betweenness' 'pagerank' 'closeness' 'eigenvector_centrality' 'degrees'] 5\n"
     ]
    }
   ],
   "source": [
    "is_lists = True\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "if is_lists:\n",
    "    parenclitics = parenclitics.select_dtypes(exclude=numerics) # includ exclude\n",
    "    parenclitics = parenclitics.drop(columns = [\"weights\", \"component_sizes\", \"id_components\"]) #   \"weights\" \n",
    "    #parenclitics = parenclitics.drop(columns = [\"eigenvalues_intervals_normalized\", \"eigenvalues_intervals\", \"IPR\", \"weights\", \"eigenvalues\"])\n",
    "else:\n",
    "    parenclitics = parenclitics.select_dtypes(include=numerics) # includ exclude\n",
    "    #parenclitics = parenclitics.drop(columns = [\"mean_pagerank\", \"max_degrees\", \"max_closeness\"])\n",
    "    parenclitics = parenclitics.drop(columns = [\"min_weights\", \"max_weights\", \"mean_weights\", \"std_weights\", \"zeros_weights\"])\n",
    "#print parenclitics\n",
    "#parenclitics = parenclitics[:29]\n",
    "\n",
    "#parenclitics = parenclitics.drop(columns = [\"std_weights\", \"max_weights\", \"mean_weights\", \"mean_pagerank\", \"mean_closeness\", \"max_closeness\"])\n",
    "\n",
    "\n",
    "#\n",
    "print (parenclitics.columns.values, len(parenclitics.columns.values))\n",
    "parenclitic_names = parenclitic_feature_names()\n",
    "parenclitic_names = [parenclitic_names[name] for name in parenclitics.columns.values]\n",
    "#ids = [0,7,11,15,16,17,18]\n",
    "#parenclitic_names = np.delete(np.array(parenclitic_names), ids)\n",
    "\n",
    "#parenclitics = parenclitics.drop(columns = parenclitics.columns[ids])\n",
    "\n",
    "parenclitics.columns = range(len(parenclitics.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups = [\"mongoloids_mask\", \"siblings_mask\", \"mothers_mask\"]\n",
    "group_masks = [0] * 3\n",
    "for j, group_name in enumerate(groups):\n",
    "    group_masks[j] = config.params[group_name].value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#\"../../../data/Down_phenotype/DOWN_FENOTIPO_No4,8,12_PerCorrelazioni.tsv\"\n",
    "phenotype_df = pd.read_csv(config.ifname(\"down_phenotypes_table\"), delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 125)\n"
     ]
    }
   ],
   "source": [
    "print phenotype_df.shape\n",
    "mask = (phenotype_df.isnull().sum() == 0)\n",
    "phenotype_df_good = phenotype_df[mask.index[mask]]\n",
    "#print phenotype_df_good\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "df = pd.DataFrame(phenotype_df)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imp.fit(df)\n",
    "phenotype_df_imputed = pd.DataFrame(imp.transform(df))\n",
    "phenotype_df_imputed.columns = phenotype_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor feature_name in feature_names:\\n    plt.figure()\\n    plt.scatter(df_pca[\"pca_0\"], df_pca[\"pca_4\"], c = phenotype_df[feature_name], cmap= \\'jet\\')\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = pd.DataFrame(phenotype_df)\n",
    "df = df.drop(['codicePID'], axis=1)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imp.fit(df)\n",
    "\n",
    "'''\n",
    "df = pd.DataFrame(parenclitics)\n",
    "#print df\n",
    "\n",
    "df = (df - df.mean()) / df.std()\n",
    "num_components = 10\n",
    "pca = PCA(n_components=num_components, svd_solver='full')\n",
    "pca.fit(df)\n",
    "\n",
    "columns = ['pca_%i' % i for i in range(num_components)]\n",
    "df_pca = pd.DataFrame(pca.transform(df), columns=columns, index=df.index)\n",
    "df_pca\n",
    "'''\n",
    "\n",
    "feature_names = [\"categoriaDSQIID\", \"fluenzaverbale\",\"ABCiperattivita\", \"ABCIrritabilita\", \"ABCletargia\", \"ABCstereotipie\", \"ABCinappropriatespeech\", \"fluenzafonemica\", \"F.A.B.\"]\n",
    "'''\n",
    "for feature_name in feature_names:\n",
    "    plt.figure()\n",
    "    plt.scatter(df_pca[\"pca_0\"], df_pca[\"pca_4\"], c = phenotype_df[feature_name], cmap= 'jet')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categoriaDSQIID\n",
      "[ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  0  1  0  0  1  0  0  0  0] good\n",
      "[ 1  1  0  1  1  0  0  0  0  1  1  0  0  1  1  1  0  1  0  1  0  1  1  1  1  0  0  0  1] 0.49 0.79 0.66 SVC\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 0.80 0.79 0.79 KNeighborsClassifier\n",
      "[ 1  1  0  1  1  0  0  0  0  0  1  0  0  1  1  1  0  1  0  1  0  1  1  0  1  0  0  0  0] 0.63 0.79 0.76 LinearSVC\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  1  0  0  1  0  0  0  0] 0.76 0.79 0.93 RandomForestClassifier\n",
      "fluenzaverbale\n",
      "[ 0  1  1  0  1  1  0  0  0  1  0  1  1  2  0  0  1  0  2  0  0  0  0  0  2] good\n",
      "[ 2  1  1  0  0  1  0  0  0  1  2  2  1  2  0  0  1  2  2  1  0  0  0  0  2] 0.37 0.56 0.76 SVC\n",
      "[ 0  1  1  0  0  0  0  0  0  0  0  1  0  0  0  0  1  0  0  0  0  0  0  0  1] 0.50 0.56 0.72 KNeighborsClassifier\n",
      "[ 0  1  1  0  0  1  1  0  0  1  0  0  1  2  0  0  1  2  2  1  0  0  0  0  2] 0.30 0.56 0.80 LinearSVC\n",
      "[ 0  1  1  0  1  1  0  0  0  1  0  0  1  2  0  0  1  0  2  0  0  0  0  0  2] 0.45 0.56 0.96 RandomForestClassifier\n",
      "ABCiperattivita\n",
      "[ 5  0 12  1  0  0  3  2  9  1  0  3 43  2  2  2  0  2  0  0  1  1  0  0  2  0  0  2] good\n",
      "[ 5  2 12  0  5  0  3  0  9  1  1  3 43  2  2  2  0  1  0  0  2  5  1  2  2 43  0  2] 0.34 0.39 0.61 SVC\n",
      "[ 0  0  2  0  0  0  0  0  3  1  0  2  0  2  2  2  0  1  0  0  1  0  0  0  2  0  0  2] 0.54 0.39 0.64 KNeighborsClassifier\n",
      "[ 5  0 12  0  5  0  3  2  9  1  0  3 43  2  2  2  0  2  0  0  1  0  0  0  2  0  0  2] 0.34 0.39 0.89 LinearSVC\n",
      "[ 5  0  2  1  0  0  3  2  9  1  0  3 43  2  2  2  2  2  0  0  2  1  0  0  2  0  0  2] 0.40 0.39 0.89 RandomForestClassifier\n",
      "ABCIrritabilita\n",
      "[ 0  1  5  2  0  0  0  3  0  0  0  1  8 16  0  0  0  0  0  1  6  3  4  0  0  0  0  3] good\n",
      "[ 4  1  5  2  3  2  0  3  0  0  4  1  8 16 16  1  0  0  2  2  6  4  4  0  0  8  2 16] 0.13 0.57 0.57 SVC\n",
      "[ 0  0  3  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  1  0  3  3  0  0  0  0  0] 0.61 0.57 0.64 KNeighborsClassifier\n",
      "[ 0  1  5  2  0  0  0  3  0  0  0  0  8 16  1  0  0  0  0  2  6  3  4  0  0  0  1  3] 0.21 0.57 0.86 LinearSVC\n",
      "[ 3  1  5  0  0  0  0  3  0  0  0  1  0 16  1  0  0  0  0  0  6  3  4  0  0  0  0  3] 0.54 0.57 0.82 RandomForestClassifier\n",
      "ABCletargia\n",
      "[17  5  0  9 27  0  2  2 10 17  6 13  0  2 14  1  6 13  0 16  0 13  0  2  0  3  1  3] good\n",
      "[27  5  0  9 27  9  0  0 10  0 13  1  0 14 14  1  6 13  9 16 14  0 13  1  0  3  9 14] 0.01 0.25 0.46 SVC\n",
      "[17  5  0  1 17  0  2  0 10 13  0  1  0  2  3  1  2 13  0  9  0  0  0  1  0  0  1  3] 0.11 0.25 0.57 KNeighborsClassifier\n",
      "[17  5  0  9 27  9  2  2 10 17  6 13  0  5 14  1  6 13  0 16  0 13 13  2  0  3  1  3] 0.04 0.25 0.89 LinearSVC\n",
      "[17  5  0  0  2  0  2  2 10 13  0 13  0  2 14  1  6 13  0 16  0 13  0  2  0  0  0  3] 0.16 0.25 0.79 RandomForestClassifier\n",
      "ABCstereotipie\n",
      "[10  0  2  3 11  0  8  0  2  8  4  0  4  2  0  2  0  3  0  5  6  9  3  0  0  0  0  1] good\n",
      "[10  0  2  3 11  0  8  0  2  8  3  0  4  1  1  0  0  8  0  5  6  9  9  0  0  4  0  1] 0.13 0.39 0.75 SVC\n",
      "[10  0  1  0 10  0  0  0  0  3  3  0  0  1  0  0  0  3  0  3  0  3  3  0  0  0  0  0] 0.31 0.39 0.50 KNeighborsClassifier\n",
      "[10  0  2  3 11  0  8  0  2  8  4  0  4  2  0  2  0  3  0  5  6  9  3  0  0  4  0  1] 0.26 0.39 0.96 LinearSVC\n",
      "[10  0  2  3 11  0  8  0  2  8  4  0  4  2  0  2  0  3  0  5  0  9  3  0  0  0  0  1] 0.26 0.39 0.96 RandomForestClassifier\n",
      "ABCinappropriatespeech\n",
      "[ 2  4  2  3  6  0  2  2  4  5  4  3  9  5  0  2  7  3  5  0  3  3  5  1  1  3  4  6] good\n",
      "[ 6  4  2  0  6  5  2  2  1  5  4  1  9  6  5  1  7  5  5  4  1  6  5  1  1  9  4  6] 0.03 0.21 0.54 SVC\n",
      "[ 2  0  2  3  2  0  1  0  3  3  4  2  3  5  0  2  2  3  0  0  0  3  3  1  1  3  3  0] 0.00 0.21 0.50 KNeighborsClassifier\n",
      "[ 6  4  2  0  6  0  2  2  4  5  4  4  9  5  0  2  7  3  5  0  3  6  0  1  1  3  4  6] 0.02 0.21 0.82 LinearSVC\n",
      "[ 2  4  2  3  6  0  2  2  4  5  4  3  9  3  0  2  7  3  0  0  3  3  5  1  1  3  0  3] 0.04 0.21 0.86 RandomForestClassifier\n",
      "fluenzafonemica\n",
      "[ 0  9  3  8  3 19  9  6  0  5  7  2  9  0  0 14  0  8  0  7  3 20  0  6  9  0  6 20] good\n",
      "[ 3  0  3  8  3 19  9 19  2  5  0  2  3 20  2 14  5  8  0  7 20 20  0  2  2  0  8 20] 0.02 0.29 0.54 SVC\n",
      "[ 0  0  3  6  0  8  6  6  0  0  7  0  0  0  0  6  0  8  0  0  3  3  0  0  2  0  6  0] 0.20 0.29 0.50 KNeighborsClassifier\n",
      "[ 3  9  3  8  3 19  9  6  0  5  7  2  9 20  2 14  0  8  0  7  3 20  7  6  9  0  6 20] 0.03 0.29 0.86 LinearSVC\n",
      "[ 3  9  3  8  3 19  9  6  0  0  7  2  9 20  0  6  0  6  0  7  3 20  0  6  7  0  6 20] 0.25 0.29 0.79 RandomForestClassifier\n",
      "F.A.B.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from scipy import stats\n",
    "from sklearn import neighbors, ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "data = parenclitics\n",
    "data = data[:29].values\n",
    "data = stats.zscore(data)\n",
    "data = data[:, ~np.all(np.isnan(data), axis=0)]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.set_printoptions(linewidth=100, formatter={'int':lambda x: \"{:2d}\".format(x), 'float':lambda x: \"{:.2f}\".format(x)})\n",
    "feature_names = [\"categoriaDSQIID\", \"fluenzaverbale\",\"ABCiperattivita\", \"ABCIrritabilita\", \"ABCletargia\", \"ABCstereotipie\", \"ABCinappropriatespeech\", \"fluenzafonemica\", \"F.A.B.\"]\n",
    "for feature_name in feature_names:\n",
    "    print (feature_name)\n",
    "    feature = (phenotype_df[feature_name].values)\n",
    "    mask = ~np.isnan(feature)\n",
    "    cur = data[mask]\n",
    "    feature = feature[mask].astype('int')\n",
    "    if (feature == 0).sum() < 3:\n",
    "        continue\n",
    "    #feature = (feature > np.median(feature)).astype('int')\n",
    "    \n",
    "    #print np.nan_to_num(phenotype_df[feature_name].values, -1).astype('int'), 'source'\n",
    "    print (feature, 'good')\n",
    "    clfs = [svm.SVC(kernel = 'rbf', C = 1, class_weight = \"balanced\"), \n",
    "            neighbors.KNeighborsClassifier(n_neighbors = 2),\n",
    "            svm.LinearSVC(C = 1, class_weight = \"balanced\"),\n",
    "            ensemble.RandomForestClassifier(n_estimators = 4)]\n",
    "\n",
    "    for clf in clfs:\n",
    "        score = cross_val_score(clf, cur, feature, cv=5).mean()\n",
    "        clf.fit(cur, feature)\n",
    "        predicted = clf.predict(cur)\n",
    "        score2 = clf.score(cur, feature)\n",
    "        val = float(np.bincount(feature).max()) / len(feature)\n",
    "        print (predicted, \"{:.2f}\".format(score), \"{:.2f}\".format(val), \"{:.2f}\".format(score2), type(clf).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PC\\\\UNN\\\\Science\\\\Gerontology\\\\data\\\\GSE52588\\\\params\\\\num_genes_14756\\\\kde_mask_mongoloids_mask\\\\algorithm_kde\\\\thr_p_0.88\\\\parenclitic_pairs_full_inside_all.pdf'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.ofname([[\"parenclitic_pairs_full_inside_all\"]], ext = \".pdf\", \n",
    "                                     include_set = config.params_sets[\"parenclitic_boxplots\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eigenvector centrality'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parenclitic_names[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\PC\\UNN\\Science\\Gerontology\\data\\GSE52588\\params\\num_cpgs_114674\\kde_mask_nonhealthy_mask\\algorithm_pdf\\thr_type_best\\division_rule_non_control\\parenclitic_pairs_all_.pdf\n",
      "Betweenness Pagerank\n",
      "(9976638,)\n",
      "Betweenness Closeness\n",
      "(9976638,)\n",
      "Betweenness Eigenvector centrality\n",
      "(9976638,)\n",
      "Betweenness Degrees\n",
      "(9976638,)\n",
      "Pagerank Betweenness\n",
      "(9976638,)\n",
      "Pagerank Closeness\n",
      "(9976638,)\n",
      "Pagerank Eigenvector centrality\n",
      "(9976638,)\n",
      "Pagerank Degrees\n",
      "(9976638,)\n",
      "Closeness Betweenness\n",
      "(9976638,)\n",
      "Closeness Pagerank\n",
      "(9976638,)\n",
      "Closeness Eigenvector centrality\n",
      "(9976638,)\n",
      "Closeness Degrees\n",
      "(9976638,)\n",
      "Eigenvector centrality Betweenness\n",
      "(9976638,)\n",
      "Eigenvector centrality Pagerank\n",
      "(9976638,)\n",
      "Eigenvector centrality Closeness\n",
      "(9976638,)\n",
      "Eigenvector centrality Degrees\n",
      "(9976638,)\n",
      "Degrees Betweenness\n",
      "(9976638,)\n",
      "Degrees Pagerank\n",
      "(9976638,)\n",
      "Degrees Closeness\n",
      "(9976638,)\n",
      "Degrees Eigenvector centrality\n",
      "(9976638,)\n"
     ]
    }
   ],
   "source": [
    "def plot_hist_2d(ax, x, y, bins, c, **kwargs):\n",
    "    h = ax.hist2d(x, y, bins = bins, cmap = 'jet', norm = matplotlib.colors.LogNorm(), **kwargs)\n",
    "    plt.colorbar(h[3], ax = ax)\n",
    "\n",
    "def plot_line(ax, x, y, **kwargs):\n",
    "    ids = np.argsort(x)\n",
    "    x, y = x[ids], y[ids]\n",
    "    ax.plot(x, y, **kwargs)\n",
    "    \n",
    "def remove_zeros(x, y):\n",
    "    eps = 1e-7\n",
    "    mask = (x > eps) & (y > eps)\n",
    "    return x[mask], y[mask]\n",
    "\n",
    "def get_interval(x, y, A, B):\n",
    "    mask = (x < A) & (y > B)\n",
    "    return x[mask], y[mask]\n",
    "\n",
    "def plot_2_2(u, v, u1, v1, u2, v2, u3, v3, u4, v4, parenclitic_names, id1_parenclitic, id2_parenclitic):\n",
    "    fig, axes = plt.subplots(2, 2, sharey = True, sharex = True, figsize = (13, 11))\n",
    "    '''\n",
    "    for i in range(29):\n",
    "        x = np.reshape(np.array(parenclitics[id1_parenclitic][i]), -1)\n",
    "        y = np.reshape(np.array(parenclitics[id2_parenclitic][i]), -1)\n",
    "        plot_line(axes[0, 0], x, y)\n",
    "\n",
    "        x = np.reshape(np.array(parenclitics[id1_parenclitic][i + 29 * 3]), -1)\n",
    "        y = np.reshape(np.array(parenclitics[id2_parenclitic][i + 29 * 3]), -1)\n",
    "        plot_line(axes[0, 1], x, y)\n",
    "\n",
    "        x = np.reshape(np.array(parenclitics[id1_parenclitic][i + 29 * 1]), -1)\n",
    "        y = np.reshape(np.array(parenclitics[id2_parenclitic][i + 29 * 1]), -1)\n",
    "        plot_line(axes[1, 0], x, y)\n",
    "\n",
    "        x = np.reshape(np.array(parenclitics[id1_parenclitic][i + 29 * 2]), -1)\n",
    "        y = np.reshape(np.array(parenclitics[id2_parenclitic][i + 29 * 2]), -1)\n",
    "        plot_line(axes[1, 1], x, y)\n",
    "\n",
    "    colors = ['red', 'green', 'blue', 'magenta']\n",
    "    for i in range(4):\n",
    "        x = np.array(parenclitics[id1_parenclitic][29 * i:29 * i + 29].values.tolist()).mean(axis = 0)\n",
    "        y = np.array(parenclitics[id2_parenclitic][29 * i:29 * i + 29].values.tolist()).mean(axis = 0)\n",
    "        plot_line(axes[0, 1], x, y, c = colors[i], linewidth = 3)\n",
    "    '''\n",
    "    nbins = 300\n",
    "    if is_log:\n",
    "        bins = [np.geomspace(u.min(), u.max(), nbins), np.geomspace(v.min(), v.max(), nbins)]\n",
    "    else:\n",
    "        bins = [np.linspace(u.min(), u.max(), nbins), np.linspace(v.min(), v.max(), nbins)]\n",
    "\n",
    "    '''\n",
    "    plot_hist_2d(axes[0,0], u2, v2, bins, c = 'red')\n",
    "    plot_hist_2d(axes[0,1], u4, v4, bins, c = 'magenta')\n",
    "    plot_hist_2d(axes[1,0], u1, v1, bins, c = 'green')\n",
    "    plot_hist_2d(axes[1,1], u3, v3, bins, c = 'blue')\n",
    "    '''\n",
    "\n",
    "    # Scatter points\n",
    "    axes[0,0].scatter(u2, v2, c = 'red', rasterized = True, alpha = 0.7)\n",
    "    axes[0,1].scatter(u4, v4, c = 'magenta', rasterized = True, alpha = 0.7)\n",
    "    axes[1,0].scatter(u1, v1, c = 'green', rasterized = True, alpha = 0.7)\n",
    "    axes[1,1].scatter(u3, v3, c = 'blue', rasterized = True, alpha = 0.7)\n",
    "\n",
    "\n",
    "    #plt.scatter(u, v, c = np.reshape(feature, -1), \n",
    "    #            cmap = plt.get_cmap('jet', feature.max() - feature.min() + 1))\n",
    "    axes[1, 0].set_xlabel(parenclitic_names[id1_parenclitic].capitalize(), fontsize = fontsize)\n",
    "    axes[1, 0].set_ylabel(parenclitic_names[id2_parenclitic].capitalize(), fontsize = fontsize)\n",
    "\n",
    "    #plt.subplots_adjust(bottom=0.2, top=0.8, left=0.25, right=0.95, wspace = 0.2)\n",
    "    plt.subplots_adjust(bottom=0.1, top=0.9, left=0.1, right=0.95, wspace = 0.05)\n",
    "\n",
    "    plt.setp(axes[0, 1].get_yticklabels(), visible=False)\n",
    "    plt.setp(axes[1, 1].get_yticklabels(), visible=False)\n",
    "\n",
    "    '''\n",
    "    axes[0, 0].set_title('DS')\n",
    "    axes[0, 1].set_title('Random graph')\n",
    "    axes[1, 0].set_title('Sibs')\n",
    "    axes[1, 1].set_title('Moms')\n",
    "    '''\n",
    "\n",
    "    axes[0,0].legend(['DS'], framealpha=0.9, fontsize=20, #bbox_to_anchor=(0., 1.02, 1., .102), \n",
    "       bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\",\n",
    "       ncol=3, mode=\"expand\", borderaxespad=0., handletextpad=0.2, scatterpoints=3, columnspacing = 2)\n",
    "    axes[0,1].legend(['Random graph'], framealpha=0.9, fontsize=20, #bbox_to_anchor=(0., 1.02, 1., .102), \n",
    "       bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\",\n",
    "       ncol=3, mode=\"expand\", borderaxespad=0., handletextpad=0.2, scatterpoints=3, columnspacing = 2)\n",
    "    axes[1,0].legend(['Sibs'], framealpha=0.9, fontsize=20, #bbox_to_anchor=(0., 1.02, 1., .102), \n",
    "       bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\",\n",
    "       ncol=3, mode=\"expand\", borderaxespad=0., handletextpad=0.2, scatterpoints=3, columnspacing = 2)\n",
    "    axes[1,1].legend(['Moms'], framealpha=0.9, fontsize=20, #bbox_to_anchor=(0., 1.02, 1., .102), \n",
    "       bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\",\n",
    "       ncol=3, mode=\"expand\", borderaxespad=0., handletextpad=0.2, scatterpoints=3, columnspacing = 2)\n",
    "\n",
    "\n",
    "    if is_log:\n",
    "        for ax in axes.flat:\n",
    "            ax.set_xscale(\"log\")\n",
    "            ax.set_yscale(\"log\")\n",
    "        delta = (np.log(u.max()) - np.log(u.min())) * 0.05\n",
    "        plt.xlim(np.exp(np.log(u.min()) - delta), np.exp(np.log(u.max()) + delta))\n",
    "\n",
    "        delta = (np.log(v.max()) - np.log(v.min())) * 0.05\n",
    "        plt.ylim(np.exp(np.log(v.min()) - delta), np.exp(np.log(v.max()) + delta))\n",
    "    else:\n",
    "        axes[0,0].ticklabel_format(scilimits = [-2, 2])\n",
    "        axes[0,1].ticklabel_format(scilimits = [-2, 2])\n",
    "        axes[1,0].ticklabel_format(scilimits = [-2, 2])\n",
    "        axes[1,1].ticklabel_format(scilimits = [-2, 2])\n",
    "        delta = (u.max() - u.min()) * 0.05\n",
    "        plt.xlim(u.min() - delta, u.max() + delta)\n",
    "\n",
    "        delta = (v.max() - v.min()) * 0.05\n",
    "        plt.ylim(v.min() - delta, v.max() + delta)    \n",
    "    return fig, axes\n",
    "\n",
    "def plot_pairs(u, v, u1, v1, u2, v2, u3, v3, u4, v4, parenclitic_names, id1_parenclitic, id2_parenclitic):\n",
    "    fig = plt.figure(figsize = (9, 7))\n",
    "    ax = plt.gca()\n",
    "    nbins = 300\n",
    "    if is_log:\n",
    "        bins = [np.geomspace(u.min(), u.max(), nbins), np.geomspace(v.min(), v.max(), nbins)]\n",
    "    else:\n",
    "        bins = [np.linspace(u.min(), u.max(), nbins), np.linspace(v.min(), v.max(), nbins)]\n",
    "    \n",
    "    ax.scatter(u2, v2, c = 'red', rasterized = True, alpha = 0.5)\n",
    "    ax.scatter(u1, v1, c = 'green', rasterized = True, alpha = 0.5)\n",
    "    ax.scatter(u3, v3, c = 'blue', rasterized = True, alpha = 0.5)\n",
    "    ax.scatter(u4, v4, c = 'magenta', rasterized = True, alpha = 0.5)\n",
    "    \n",
    "    ax.set_xlabel(parenclitic_names[id1_parenclitic].capitalize(), fontsize = fontsize)\n",
    "    ax.set_ylabel(parenclitic_names[id2_parenclitic].capitalize(), fontsize = fontsize)\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.15, top=0.9, left=0.2, right=0.95, wspace = 0.05)\n",
    "\n",
    "    ax.legend(['DS', 'Sibs', 'Moms', 'Random graph'], framealpha=0.9, fontsize=20, #bbox_to_anchor=(0., 1.02, 1., .102), \n",
    "       bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\",\n",
    "       ncol=4, mode=\"expand\", borderaxespad=0., handletextpad=0.2, scatterpoints=3, columnspacing = 1)\n",
    "    \n",
    "    if is_log:\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "        delta = (np.log(u.max()) - np.log(u.min())) * 0.05\n",
    "        plt.xlim(np.exp(np.log(u.min()) - delta), np.exp(np.log(u.max()) + delta))\n",
    "\n",
    "        delta = (np.log(v.max()) - np.log(v.min())) * 0.05\n",
    "        plt.ylim(np.exp(np.log(v.min()) - delta), np.exp(np.log(v.max()) + delta))\n",
    "    else:\n",
    "        ax.ticklabel_format(scilimits = [-2, 2])\n",
    "        delta = (u.max() - u.min()) * 0.05\n",
    "        plt.xlim(u.min() - delta, u.max() + delta)\n",
    "\n",
    "        delta = (v.max() - v.min()) * 0.05\n",
    "        plt.ylim(v.min() - delta, v.max() + delta)    \n",
    "    return fig, ax\n",
    "\n",
    "from tqdm import tqdm\n",
    "#\"categoriaDSQIID\", \"fluenzaverbale\",\"ABCiperattivita\", \"ABCIrritabilita\", \"ABCletargia\", \"ABCstereotipie\", \"ABCinappropriatespeech\", \"fluenzafonemica\", \"F.A.B.\"\n",
    "data = parenclitics\n",
    "#data = data[:29]\n",
    "data = data.values\n",
    "#data = stats.zscore(data)\n",
    "feature_name = \"ABCinappropriatespeech\"\n",
    "df_ans = None\n",
    "is_log = False\n",
    "\n",
    "parenclitic_pairs_path = config.ofname([[\"parenclitic_pairs_all\", \"log\" if is_log else \"\"]], \n",
    "                                       ext = \".pdf\", \n",
    "                                       include_set = config.params_sets[\"parenclitic_boxplots\"])\n",
    "print(parenclitic_pairs_path)\n",
    "with PdfPages(parenclitic_pairs_path) as pdf:\n",
    "    for id1_parenclitic in range(data.shape[1]):\n",
    "        for id2_parenclitic in range(data.shape[1]):\n",
    "            '''\n",
    "            parenclitic_pairs_path = config.ofname([[\"parenclitic_pairs_hist\"], \n",
    "                                                    [\"parenclitic_pairs_all_hist\", \n",
    "                                                     parenclitic_names[id1_parenclitic], \n",
    "                                                     parenclitic_names[id2_parenclitic]]], \n",
    "                                                   ext = \".pdf\", \n",
    "                                                   include_set = config.params_sets[\"parenclitic_boxplots\"])\n",
    "            print(parenclitic_pairs_path)\n",
    "            '''\n",
    "            for id_subject in [0]: # tqdm(range(29))\n",
    "                if id1_parenclitic == id2_parenclitic: \n",
    "                    continue\n",
    "                id_parenclitic = [id1_parenclitic, id2_parenclitic]\n",
    "                print (parenclitic_names[id1_parenclitic], parenclitic_names[id2_parenclitic])\n",
    "                #cur = data[:, id_parenclitic]\n",
    "                #val = np.arctan2(cur[:, 0] - cur[0, 0], cur[:, 1] - cur[0, 1]) % np.pi\n",
    "                #print val[val != 0] #(cur[:, 0] - cur[0, 0].min()) / (cur[:, 1] - cur[:, 1].min())\n",
    "                #if np.std(val[val != 0]) < 1e-3:\n",
    "                #    continue\n",
    "\n",
    "                #cur = cur[:29]\n",
    "\n",
    "                #feature = np.reshape(y == 0, -1)\n",
    "\n",
    "                #u = np.reshape(np.array(parenclitics[id1_parenclitic][29:58]).tolist(), -1)\n",
    "                #v = np.reshape(np.array(parenclitics[id2_parenclitic][29:58]).tolist(), -1)\n",
    "                #print(u.shape, u.dtype)\n",
    "\n",
    "                #plt.figure(figsize = (7, 5))\n",
    "                #plt.figure()\n",
    "                num = 29\n",
    "                u4 = np.reshape(np.array(parenclitics[id1_parenclitic][29 * 3 + id_subject:29 * 3 + num + id_subject]).tolist(), -1)\n",
    "                v4 = np.reshape(np.array(parenclitics[id2_parenclitic][29 * 3 + id_subject:29 * 3 + num + id_subject]).tolist(), -1)\n",
    "\n",
    "                u3 = np.reshape(np.array(parenclitics[id1_parenclitic][29 * 2 + id_subject:29 * 2 + num + id_subject]).tolist(), -1)\n",
    "                v3 = np.reshape(np.array(parenclitics[id2_parenclitic][29 * 2 + id_subject:29 * 2 + num + id_subject]).tolist(), -1)\n",
    "\n",
    "                u2 = np.reshape(np.array(parenclitics[id1_parenclitic][29 * 0 + id_subject:29 * 0 + num + id_subject]).tolist(), -1)\n",
    "                v2 = np.reshape(np.array(parenclitics[id2_parenclitic][29 * 0 + id_subject:29 * 0 + num + id_subject]).tolist(), -1)\n",
    "\n",
    "                u1 = np.reshape(np.array(parenclitics[id1_parenclitic][29 * 1 + id_subject:29 * 1 + num + id_subject]).tolist(), -1)\n",
    "                v1 = np.reshape(np.array(parenclitics[id2_parenclitic][29 * 1 + id_subject:29 * 1 + num + id_subject]).tolist(), -1)\n",
    "\n",
    "                #u1, v1 = remove_zeros(u1, v1)\n",
    "                #u2, v2 = remove_zeros(u2, v2)\n",
    "                #u3, v3 = remove_zeros(u3, v3)\n",
    "                #u4, v4 = remove_zeros(u4, v4)\n",
    "\n",
    "                #u = np.concatenate([u1, u2, u3, u4])\n",
    "                #v = np.concatenate([v1, v2, v3, v4])\n",
    "\n",
    "                u = np.reshape(np.array(parenclitics[id1_parenclitic][:]).tolist(), -1)\n",
    "                v = np.reshape(np.array(parenclitics[id2_parenclitic][:]).tolist(), -1)\n",
    "                print(u.shape)\n",
    "                #u, v = remove_zeros(u, v)\n",
    "                \n",
    "\n",
    "                #if np.ptp(u) < 1e-8 or np.ptp(v) < 1e-8:\n",
    "                #    continue\n",
    "\n",
    "                colors = np.zeros_like(u)\n",
    "                colors[-len(u2)-len(u3):] = 1\n",
    "                colors[-len(u3):] = 2\n",
    "\n",
    "\n",
    "                #fig, axes = plot_2_2(u, v, u1, v1, u2, v2, u3, v3, u4, v4, parenclitic_names, id1_parenclitic, id2_parenclitic)\n",
    "                fig, ax = plot_pairs(u, v, u1, v1, u2, v2, u3, v3, u4, v4, parenclitic_names, id1_parenclitic, id2_parenclitic)\n",
    "\n",
    "                \n",
    "                #plt.title(feature_name, fontsize = fontsize)\n",
    "                #plt.colorbar()\n",
    "                pdf.savefig(dpi = 300)\n",
    "                #parenclitic_pairs_path = config.ofname([[\"parenclitic_pairs_full_inside_down\"], [parenclitic_names[id1_parenclitic], parenclitic_names[id2_parenclitic]]], ext = \".png\", \n",
    "                #                         include_set = config.params_sets[\"parenclitic_boxplots\"])\n",
    "                #plt.savefig(parenclitic_pairs_path)\n",
    "                #plt.show()\n",
    "                plt.close()\n",
    "                #sdf\n",
    "\n",
    "                continue\n",
    "\n",
    "\n",
    "                feature = (phenotype_df[feature_name].values)\n",
    "                feature = feature[:29]\n",
    "\n",
    "                mask = ~np.isnan(feature)\n",
    "                #cur = cur[mask]\n",
    "                u = u[mask]\n",
    "                v = v[mask]\n",
    "                cur = cur[mask]\n",
    "                #cur = cur.reshape(-1, 1)\n",
    "                feature = feature[mask].astype('int')\n",
    "                feature = np.minimum(feature, 12)\n",
    "                #if (feature == 0).sum() < 3:\n",
    "                #    continue\n",
    "                #feature = (feature > np.median(feature)).astype('int')\n",
    "\n",
    "                #print np.nan_to_num(phenotype_df[feature_name].values, -1).astype('int'), 'source'\n",
    "                #print feature, 'good'\n",
    "                clfs = [svm.SVC(kernel = 'rbf', C = 1, class_weight = \"balanced\"), \n",
    "                        neighbors.KNeighborsClassifier(n_neighbors = 2),\n",
    "                        svm.LinearSVC(C = 1, class_weight = \"balanced\"),\n",
    "                        ensemble.RandomForestClassifier(n_estimators = 4)]\n",
    "                df_cur = pd.DataFrame(index=[0])\n",
    "\n",
    "                #df_ans[parenclitic_names[id_parenclitic]] = parenclitics[id_parenclitic]\n",
    "                #df_ans[\"input\"] = cur\n",
    "                #df_ans[\"good\"] = feature\n",
    "                #'''\n",
    "\n",
    "                #plt.scatter(np.reshape(parenclitics[id_parenclitic], -1), np.reshape(np.zeros_like(cur), -1), c = np.reshape(feature, -1), cmap = 'jet')\n",
    "                #'''\n",
    "                df_cur['parenclitic_1'] = parenclitic_names[id1_parenclitic]\n",
    "                df_cur['parenclitic_2'] = parenclitic_names[id2_parenclitic]\n",
    "                for clf in clfs:\n",
    "                    score = cross_val_score(clf, cur, feature, cv=5, scoring = \"neg_mean_absolute_error\")\n",
    "\n",
    "                    clf.fit(cur, feature)\n",
    "                    predicted = clf.predict(cur)\n",
    "                    score2 = np.mean(np.abs(feature - np.around(predicted).astype(\"int\")))\n",
    "                    score_median = np.mean(np.abs(feature - np.median(feature)))\n",
    "                    clf_name = type(clf).__name__\n",
    "                    df_cur[clf_name + '_score_cv'] = -score.mean()\n",
    "                    df_cur[clf_name + '_score_best'] = score2\n",
    "                    #print np.around(predicted).astype(\"int\"), \"{:.2f}\".format(-score.mean()), \"{:.2f}\".format(score_median), \"{:.2f}\".format(score2), clf_name\n",
    "\n",
    "                    '''\n",
    "                    score = cross_val_score(clf, cur, feature, cv=5).mean()\n",
    "                    clf.fit(cur, feature)\n",
    "                    predicted = clf.predict(cur)\n",
    "                    score2 = clf.score(cur, feature)\n",
    "                    val = float(max((feature == 0).sum(), (feature == 1).sum())) / len(feature)\n",
    "                    clf_name = type(clf).__name__\n",
    "                    #df_ans[clf_name] = predicted\n",
    "                    print predicted, \"{:.2f}\".format(score), \"{:.2f}\".format(val), \"{:.2f}\".format(score2), clf_name\n",
    "                    '''\n",
    "                if df_ans is None:\n",
    "                    df_ans = df_cur\n",
    "                else:\n",
    "                    df_ans = df_ans.append (df_cur, ignore_index=True)\n",
    "                #plt.show()\n",
    "                pd.set_option('display.width', 100)\n",
    "                #print df_ans\n",
    "            #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00010349824052991099 91879242.73962077\n"
     ]
    }
   ],
   "source": [
    "print(u.min(), u.max())\n",
    "#bins = np.linspace(u.min, u.max(), nbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 5)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28]\n",
      "[29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52\n",
      " 53 54 55 56 57]\n",
      "[58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81\n",
      " 82 83 84 85 86]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([4., 4., 3., 3., 4., 3., 3., 0., 3., 2.]),\n",
       " array([1049. , 1594.6, 2140.2, 2685.8, 3231.4, 3777. , 4322.6, 4868.2,\n",
       "        5413.8, 5959.4, 6505. ]),\n",
       " <a list of 1 Patch objects>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_interval(x, y, A, B):\n",
    "    mask = (x < A) & (y > B)\n",
    "    return x[mask], y[mask]\n",
    "\n",
    "print(parenclitics.shape)\n",
    "data = []\n",
    "for cur_mask in group_masks:\n",
    "    print(cur_mask)\n",
    "    u = parenclitics[1][cur_mask].values\n",
    "    v = parenclitics[3][cur_mask].values\n",
    "    A = 2e-5\n",
    "    B = 5e-5\n",
    "    for i in range(len(u)):\n",
    "        x, y = u[i], v[i]\n",
    "        #print(len(x))\n",
    "        #print(x.ptp())\n",
    "        x, y = get_interval(x, y, A, B)\n",
    "        #print(len(x))\n",
    "        #plt.figure()\n",
    "        #print(x.min(), x.max(), x.ptp())\n",
    "        #plt.hist(y, bins = 100)\n",
    "        data.append(len(x))\n",
    "\n",
    "#print(data)\n",
    "data = np.array(data)\n",
    "plt.hist(data[:29], color = 'r', histtype = 'step')\n",
    "plt.hist(data[29:29 * 2], color = 'g', histtype = 'step')\n",
    "plt.hist(data[29 * 2:29 * 3], color = 'b', histtype = 'step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "u = parenclitics[1][cur_mask].values\n",
    "v = parenclitics[3][cur_mask].values\n",
    "x, y = get_interval(x, y, A, B)\n",
    "plt.hist(v, 100)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betweenness Pagerank\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1f2dbad98851>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparenclitics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid1_parenclitic\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\"categoriaDSQIID\", \"fluenzaverbale\",\"ABCiperattivita\", \"ABCIrritabilita\", \"ABCletargia\", \"ABCstereotipie\", \"ABCinappropriatespeech\", \"fluenzafonemica\", \"F.A.B.\"\n",
    "data = parenclitics\n",
    "#data = data[:29]\n",
    "data = data.values\n",
    "#data = stats.zscore(data)\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "feature_name = \"categoriaDSQIID\"\n",
    "df_ans = None\n",
    "#parenclitic_pairs_path = config.ofname([[\"parenclitic_pairs\"]], ext = \".pdf\", \n",
    "#                                     include_set = config.params_sets[\"parenclitic_boxplots\"])\n",
    "    \n",
    "#with PdfPages(parenclitic_pairs_path) as pdf:\n",
    "#with 1 as pdf:\n",
    "for id1_parenclitic in range(data.shape[1]):\n",
    "    for id2_parenclitic in range(data.shape[1]):\n",
    "        if id1_parenclitic == id2_parenclitic: \n",
    "            continue\n",
    "        id_parenclitic = [id1_parenclitic, id2_parenclitic]\n",
    "        print (parenclitic_names[id1_parenclitic], parenclitic_names[id2_parenclitic])\n",
    "        #cur = data[:, id_parenclitic]\n",
    "        #val = np.arctan2(cur[:, 0] - cur[0, 0], cur[:, 1] - cur[0, 1]) % np.pi\n",
    "        #print val[val != 0] #(cur[:, 0] - cur[0, 0].min()) / (cur[:, 1] - cur[:, 1].min())\n",
    "        #if np.std(val[val != 0]) < 1e-3:\n",
    "        #    continue\n",
    "\n",
    "        #cur = cur[:29]\n",
    "\n",
    "        #feature = np.reshape(y == 0, -1)\n",
    "\n",
    "        #u = np.reshape(np.array(parenclitics[id1_parenclitic][29:58]).tolist(), -1)\n",
    "        #v = np.reshape(np.array(parenclitics[id2_parenclitic][29:58]).tolist(), -1)\n",
    "        #print(u.shape, u.dtype)\n",
    "\n",
    "        plt.figure(figsize = (7, 5))\n",
    "        plt.figure()\n",
    "        \n",
    "        mask = ~np.isnan(feature)\n",
    "        \n",
    "        num = len(parenclitics[id1_parenclitic][0])\n",
    "        print(num)\n",
    "        \n",
    "        u = np.reshape(np.array(parenclitics[id1_parenclitic][mask]).tolist(), -1)\n",
    "        v = np.reshape(np.array(parenclitics[id2_parenclitic][mask]).tolist(), -1)\n",
    "\n",
    "        feature = (phenotype_df[feature_name].values)\n",
    "        feature = feature[:29]\n",
    "        feature = feature[mask].astype('int')        \n",
    "        \n",
    "        colors = np.zeros_like(u)\n",
    "        colors[-len(u2):] = 1\n",
    "\n",
    "        #plt.scatter(u, v, c = colors, rasterized = True, alpha = 0.1, cmap = plt.get_cmap('jet', 2))\n",
    "\n",
    "        plt.scatter(u, v, c = np.reshape(np.tile(feature, (num, 1)), -1), \n",
    "                    cmap = plt.get_cmap('jet', feature.max() - feature.min() + 1))\n",
    "        plt.xlabel(parenclitic_names[id1_parenclitic].capitalize(), fontsize = fontsize)\n",
    "        plt.ylabel(parenclitic_names[id2_parenclitic].capitalize(), fontsize = fontsize)\n",
    "        delta = (u.max() - u.min()) * 0.05\n",
    "        plt.xlim(u.min() - delta, u.max() + delta)\n",
    "\n",
    "        delta = (v.max() - v.min()) * 0.05\n",
    "        plt.ylim(v.min() - delta, v.max() + delta)\n",
    "        plt.subplots_adjust(bottom=0.2, top=0.9, left=0.25, right=0.95)\n",
    "        #plt.yscale('log')\n",
    "\n",
    "        #plt.title(feature_name, fontsize = fontsize)\n",
    "        #plt.colorbar()\n",
    "        #pdf.savefig(dpi = 300)\n",
    "        parenclitic_pairs_path = config.ofname([[\"parenclitic_pairs_full\"], [parenclitic_names[id1_parenclitic], parenclitic_names[id2_parenclitic]]], ext = \".png\", \n",
    "                                 include_set = config.params_sets[\"parenclitic_boxplots\"])\n",
    "        plt.savefig(parenclitic_pairs_path)\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "        #sdf\n",
    "        continue\n",
    "\n",
    "\n",
    "        feature = np.minimum(feature, 12)\n",
    "        #if (feature == 0).sum() < 3:\n",
    "        #    continue\n",
    "        #feature = (feature > np.median(feature)).astype('int')\n",
    "\n",
    "        #print np.nan_to_num(phenotype_df[feature_name].values, -1).astype('int'), 'source'\n",
    "        #print feature, 'good'\n",
    "        clfs = [svm.SVC(kernel = 'rbf', C = 1, class_weight = \"balanced\"), \n",
    "                neighbors.KNeighborsClassifier(n_neighbors = 2),\n",
    "                svm.LinearSVC(C = 1, class_weight = \"balanced\"),\n",
    "                ensemble.RandomForestClassifier(n_estimators = 4)]\n",
    "        df_cur = pd.DataFrame(index=[0])\n",
    "\n",
    "        #df_ans[parenclitic_names[id_parenclitic]] = parenclitics[id_parenclitic]\n",
    "        #df_ans[\"input\"] = cur\n",
    "        #df_ans[\"good\"] = feature\n",
    "        #'''\n",
    "\n",
    "        #plt.scatter(np.reshape(parenclitics[id_parenclitic], -1), np.reshape(np.zeros_like(cur), -1), c = np.reshape(feature, -1), cmap = 'jet')\n",
    "        #'''\n",
    "        df_cur['parenclitic_1'] = parenclitic_names[id1_parenclitic]\n",
    "        df_cur['parenclitic_2'] = parenclitic_names[id2_parenclitic]\n",
    "        for clf in clfs:\n",
    "            score = cross_val_score(clf, cur, feature, cv=5, scoring = \"neg_mean_absolute_error\")\n",
    "\n",
    "            clf.fit(cur, feature)\n",
    "            predicted = clf.predict(cur)\n",
    "            score2 = np.mean(np.abs(feature - np.around(predicted).astype(\"int\")))\n",
    "            score_median = np.mean(np.abs(feature - np.median(feature)))\n",
    "            clf_name = type(clf).__name__\n",
    "            df_cur[clf_name + '_score_cv'] = -score.mean()\n",
    "            df_cur[clf_name + '_score_best'] = score2\n",
    "            #print np.around(predicted).astype(\"int\"), \"{:.2f}\".format(-score.mean()), \"{:.2f}\".format(score_median), \"{:.2f}\".format(score2), clf_name\n",
    "\n",
    "            '''\n",
    "            score = cross_val_score(clf, cur, feature, cv=5).mean()\n",
    "            clf.fit(cur, feature)\n",
    "            predicted = clf.predict(cur)\n",
    "            score2 = clf.score(cur, feature)\n",
    "            val = float(max((feature == 0).sum(), (feature == 1).sum())) / len(feature)\n",
    "            clf_name = type(clf).__name__\n",
    "            #df_ans[clf_name] = predicted\n",
    "            print predicted, \"{:.2f}\".format(score), \"{:.2f}\".format(val), \"{:.2f}\".format(score2), clf_name\n",
    "            '''\n",
    "        if df_ans is None:\n",
    "            df_ans = df_cur\n",
    "        else:\n",
    "            df_ans = df_ans.append (df_cur, ignore_index=True)\n",
    "        #plt.show()\n",
    "        pd.set_option('display.width', 100)\n",
    "        #print df_ans\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PC\\\\UNN\\\\Science\\\\Gerontology\\\\data\\\\GSE52588\\\\params\\\\num_genes_14756\\\\kde_mask_mongoloids_mask\\\\algorithm_kde\\\\parenclitic_pairs\\\\Robustness_Max component size norm edges.png'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parenclitic_pairs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCiperattivita\n",
      "[ 5  0 12  1  0  0  3  2  9  1  0  3 43  2  2  2  0  2  0  0  1  1  0  0  2  0  0  2] input std = 8.11 iqr = 5.47\n",
      "[ 5  0 12  1  0  0  3  2  9  1  0  3 43  2  2  2  0  2  0  0  1  1  0  0  2  0  0  2] 39.02 3.11 0.00 LinearSVR\n",
      "[ 2  1  6  2  0  0  6  1  6  2  2  2 22  2  1  2  1  2  0  0  0  0  0  1  2  0  1  2] 2.46 3.11 1.75 KNeighborsRegressor\n",
      "[ 5  0 12  1  0  0  3  2  9  1  0  3 43  2  2  2  0  2  0  0  1  1  0  0  2  0  0  2] 4.41 3.11 0.00 LinearRegression\n",
      "[ 4  1  3  3  0  0  4  2  9  1  0  2 32 12  2  2  1  0  0  0  1  1  0  0  1  0  0  2] 4.61 3.11 1.43 RandomForestRegressor\n",
      "ABCIrritabilita\n",
      "[ 0  1  5  2  0  0  0  3  0  0  0  1  8 16  0  0  0  0  0  1  6  3  4  0  0  0  0  3] input std = 3.44 iqr = 3.65\n",
      "[ 0  1  5  2  0  0  0  3  0  0  0  1  8 16  0  0  0  0  0  1  6  3  4  0  0  0  0  3] 22.99 1.89 0.00 LinearSVR\n",
      "[ 0  0  4  1  0  0  0  2  0  0  0  0  4 11  0  0  0  0  0  0  3  2  2  0  0  3  0  2] 1.96 1.89 0.89 KNeighborsRegressor\n",
      "[ 0  1  5  2  0  0  0  3  0  0  0  1  8 16  0  0  0  0  0  1  6  3  4  0  0  0  0  3] 3.13 1.89 0.00 LinearRegression\n",
      "[ 0  0  4  1  0  0  1  3  0  0  1  0  7  8  0  0  0  0  0  1  7  2  4  0  0  0  4  3] 2.44 1.89 0.75 RandomForestRegressor\n",
      "ABCletargia\n",
      "[17  5  0  9 27  0  2  2 10 17  6 13  0  2 14  1  6 13  0 16  0 13  0  2  0  3  1  3] input std = 7.06 iqr = 8.50\n",
      "[17  5  0  9 27  0  2  2 10 17  6 13  0  2 14  1  6 13  0 16  0 13  0  2  0  3  1  3] 79.19 5.57 0.00 LinearSVR\n",
      "[11 10  4 11 14  3  6  4  6 15 10 10  3  1 10  7  4  7  3  9 14  8  1  8  6  2  7  2] 6.59 5.57 4.43 KNeighborsRegressor\n",
      "[17  5  0  9 27  0  2  2 10 17  6 13  0  2 14  1  6 13  0 16  0 13  0  2  0  3  1  3] 6.14 5.57 0.00 LinearRegression\n",
      "[17  7  3  6 20  3  2  2 10 17  5  7  3  2  8  4  8  6  0 15  0 12  4  2  0  7  3  6] 5.81 5.57 2.18 RandomForestRegressor\n",
      "ABCstereotipie\n",
      "[10  0  2  3 11  0  8  0  2  8  4  0  4  2  0  2  0  3  0  5  6  9  3  0  0  0  0  1] input std = 3.39 iqr = 4.82\n",
      "[10  0  2  3 11  0  8  0  2  8  4  0  4  2  0  2  0  3  0  5  6  9  3  0  0  0  0  1] 35.54 2.61 0.00 LinearSVR\n",
      "[ 5  0  2  3  6  0  5  2  5  4  2  2  2  4  0  2  1  2  2  2  8  4  2  2  2  3  2  4] 2.81 2.61 2.04 KNeighborsRegressor\n",
      "[10  0  2  3 11  0  8  0  2  8  4  0  4  2  0  2  0  3  0  5  6  9  3  0  0  0  0  1] 2.52 2.61 0.00 LinearRegression\n",
      "[10  0  2  2  6  0  3  0  2  6  4  1  4  2  2  2  2  3  0  2  6  8  2  0  0  0  0  0] 2.88 2.61 0.86 RandomForestRegressor\n",
      "ABCinappropriatespeech\n",
      "[ 2  4  2  3  6  0  2  2  4  5  4  3  9  5  0  2  7  3  5  0  3  3  5  1  1  3  4  6] input std = 2.12 iqr = 3.32\n",
      "[ 2  4  2  3  6  0  2  2  4  5  4  3  9  5  0  2  7  3  5  0  3  3  5  1  1  3  4  6] 41.17 1.64 0.00 LinearSVR\n",
      "[ 3  2  2  3  3  4  3  3  3  4  4  4  8  4  2  2  4  2  4  0  4  2  3  2  2  3  4  4] 1.95 1.64 1.14 KNeighborsRegressor\n",
      "[ 2  4  2  3  6  0  2  2  4  5  4  3  9  5  0  2  7  3  5  0  3  3  5  1  1  3  4  6] 1.83 1.64 0.00 LinearRegression\n",
      "[ 2  4  5  6  6  2  4  2  4  2  4  3  8  5  0  2  5  4  4  1  3  4  4  3  2  2  4  6] 2.22 1.64 0.89 RandomForestRegressor\n",
      "qiv\n",
      "[19 43 38 56 48 63 60 54 51 51 59 53 47 34 39 62 19 56 19 55 52 62 19 48 55 57 39 57] input std = 13.61 iqr = 21.50\n",
      "[19 43 38 56 48 63 60 54 51 51 59 53 47 34 39 62 19 56 19 55 52 62 19 48 55 57 39 57] 520.25 10.25 0.00 LinearSVR\n",
      "[31 38 47 38 56 62 56 56 56 52 56 56 54 38 29 50 29 58 34 52 50 55 34 34 37 56 29 58] 12.75 10.25 7.21 KNeighborsRegressor\n",
      "[19 43 38 56 48 63 60 54 51 51 59 53 47 34 39 62 19 56 19 55 52 62 19 48 55 57 39 57] 13.58 10.25 0.00 LinearRegression\n",
      "[38 38 38 47 48 61 59 55 52 54 58 53 47 34 42 62 35 55 24 55 56 59 28 48 38 43 48 58] 13.21 10.25 4.43 RandomForestRegressor\n",
      "qip\n",
      "[19 44 39 67 52 65 65 53 49 55 56 54 36 34 44 52 19 53 19 59 47 53 19 54 50 66 36 63] input std = 14.46 iqr = 23.33\n",
      "[19 44 39 67 52 65 65 53 49 55 56 54 36 34 44 52 19 53 19 59 47 53 19 54 50 66 36 63] 524.12 11.00 0.00 LinearSVR\n",
      "[32 39 53 43 58 58 57 54 57 54 55 55 44 39 32 48 32 54 36 56 50 54 36 36 34 62 28 64] 12.45 11.00 7.86 KNeighborsRegressor\n",
      "[19 44 39 67 52 65 65 53 49 55 56 54 36 34 44 52 19 53 19 59 47 53 19 54 50 66 36 63] 14.71 11.00 0.00 LinearRegression\n",
      "[28 44 34 60 52 65 46 44 53 54 47 37 43 34 40 44 34 44 19 57 52 32 32 45 42 66 44 56] 15.66 11.00 7.00 RandomForestRegressor\n",
      "token\n",
      "[ 0 25 21 18  0 35 28 20 25 10 31 12 17 10 18 25  8 24  0 23 15 27  0 14 27 21 15 27] input std = 9.68 iqr = 14.97\n",
      "[ 0 25 21 18  0 35 28 20 25 10 31 12 17 10 18 25  8 24  0 23 15 27  0 14 27 21 15 27] 194.89 7.93 0.00 LinearSVR\n",
      "[12 18 20 13 18 30 26 26 26 11 22 22 21 18 13 22 13 28  7 12 14 20  7 11 18 22 12 28] 8.01 7.93 5.57 KNeighborsRegressor\n",
      "[ 0 25 21 18  0 35 28 20 25 10 31 12 17 10 18 25  8 24  0 23 15 27  0 14 27 21 15 27] 9.52 7.93 0.00 LinearRegression\n",
      "[ 7 26 24 17 10 26 26 16 28 11 23  9 25 10 19 25 15 14  6 23 15 24  0 14 18  8 15 23] 10.36 7.93 4.04 RandomForestRegressor\n",
      "fluenzafonemica\n",
      "[ 0  9  3  8  3 19  9  6  0  5  7  2  9  0  0 14  0  8  0  7  3 20  0  6  9  0  6 20] input std = 5.98 iqr = 9.82\n",
      "[ 0  9  3  8  3 19  9  6  0  5  7  2  9  0  0 14  0  8  0  7  3 20  0  6  9  0  6 20] 67.51 4.61 0.00 LinearSVR\n",
      "[ 4  4  6  4 11 16  4  6  4  4  4  4 12  4  0  7  0  8  3  5  4 13  3  3  4  4  3 14] 5.16 4.61 3.32 KNeighborsRegressor\n",
      "[ 0  9  3  8  3 19  9  6  0  5  7  2  9  0  0 14  0  8  0  7  3 20  0  6  9  0  6 20] 4.97 4.61 0.00 LinearRegression\n",
      "[ 0  9  6  8  2 19  9  6  5  6  7  3  2  0  0  7  5  8  7  6  4 12  0  9  4  1  6 10] 5.92 4.61 2.36 RandomForestRegressor\n",
      "F.A.B.\n",
      "[ 1 11  8  7 14 11  7  5  7  9  6  6  7 14  5  7 11  5 12  4  4  8  4 10 13] input std = 3.35 iqr = 4.90\n",
      "[ 1 11  8  7 14 11  7  5  7  9  6  6  7 14  5  7 11  5 12  4  4  8  4 10 13] 41.25 2.68 0.00 LinearSVR\n",
      "[ 6  8 11 10 14  8  7  8  7 12  8  8  6 10  6  6  9  4  8  4  4  6  8  8 12] 3.35 2.68 2.00 KNeighborsRegressor\n",
      "[ 1 11  8  7 14 11  7  5  7  9  6  6  7 14  5  7 11  5 12  4  4  8  4 10 13] 2.95 2.68 0.00 LinearRegression\n",
      "[ 6 11  8  7 14 11  7  6  7  8  7  6  9 14  7  6  9  6 12  7  4  9  6  9 10] 3.04 2.68 1.04 RandomForestRegressor\n"
     ]
    }
   ],
   "source": [
    "#data = parenclitics.drop(columns = [0,7,11,15,16,17,18])\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#data = parenclitics\n",
    "#data = data[:29].values\n",
    "data = np.array(X)\n",
    "data = data[:29]\n",
    "data = stats.zscore(data)\n",
    "data = data[:, ~np.all(np.isnan(data), axis=0)]\n",
    "\n",
    "feature_names = [\"ABCiperattivita\", \"ABCIrritabilita\", \"ABCletargia\", \"ABCstereotipie\", \"ABCinappropriatespeech\", \"qiv\", \"qip\", \"token\", \"fluenzafonemica\", \"F.A.B.\"]\n",
    "np.set_printoptions(linewidth=100, formatter={'int':lambda x: \"{:2d}\".format(x), 'float':lambda x: \"{:.2f}\".format(x)})\n",
    "for feature_name in feature_names:\n",
    "    print (feature_name)\n",
    "    feature = (phenotype_df[feature_name].values)\n",
    "    \n",
    "    cur = data[~np.isnan(feature)]\n",
    "    feature = feature[~np.isnan(feature)].astype('int')\n",
    "    #print np.nan_to_num(phenotype_df[feature_name].values, 9).astype('int'), 'source'\n",
    "    print (feature, 'input', 'std =', \"{:.2f}\".format(np.std(feature)), 'iqr =', \"{:.2f}\".format(scipy.stats.iqr(feature, rng=(5, 95)) / 2))\n",
    "    clfs = [svm.LinearSVR(), \n",
    "            neighbors.KNeighborsRegressor(n_neighbors = 2),\n",
    "            linear_model.LinearRegression(),\n",
    "            ensemble.RandomForestRegressor(n_estimators = 4),\n",
    "            #neural_network.MLPRegressor(max_iter = 50, hidden_layer_sizes = (100, ))\n",
    "            ]\n",
    "\n",
    "    for clf in clfs:\n",
    "        score = cross_val_score(clf, cur, feature, cv=20, scoring = \"neg_mean_absolute_error\")\n",
    "        \n",
    "        clf.fit(cur, feature)\n",
    "        predicted = clf.predict(cur)\n",
    "        score2 = np.mean(np.abs(feature - np.around(predicted).astype(\"int\")))\n",
    "        score_median = np.mean(np.abs(feature - np.median(feature)))\n",
    "        print (np.around(predicted).astype(\"int\"), \"{:.2f}\".format(-score.mean()), \"{:.2f}\".format(score_median), \"{:.2f}\".format(score2), type(clf).__name__)\n",
    "        #print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.multicomp\n",
    "import scipy.stats as stats\n",
    "\n",
    "def calc_anova_f_oneway(data, y):\n",
    "    num_groups = 5\n",
    "    bins = np.array(np.percentile(data, np.linspace(0, 100, num_groups + 1)))\n",
    "    classes = np.minimum(np.digitize(data, bins), num_groups) - 1\n",
    "    classes = classes.flatten()\n",
    "    res = np.array(y)\n",
    "    for c in range(5):\n",
    "        res[classes == c] = y[classes == c].mean()\n",
    "    model = stats.f_oneway(y[classes == 0], y[classes == 1], y[classes == 2], y[classes == 3], y[classes == 4])\n",
    "    return model.pvalue, res\n",
    "\n",
    "def input_feature_assessment_regr(cur, feature, clf):\n",
    "    if type(clf) is str:\n",
    "        if clf == \"anova_f_oneway\":\n",
    "            return calc_anova_f_oneway(cur, feature)\n",
    "\n",
    "        if clf == \"anova_ols\":\n",
    "            cur = sm.add_constant(cur)\n",
    "            model = sm.OLS(feature, cur).fit()\n",
    "            return model.pvalues[1], model.predict(cur)\n",
    "    #score = cross_val_score(clf, cur, feature, cv=20, scoring = \"neg_mean_absolute_error\")\n",
    "    \n",
    "    clf.fit(cur, feature)\n",
    "    predicted = clf.predict(cur)\n",
    "    score2 = np.mean(np.abs(feature - np.around(predicted).astype(\"int\")))\n",
    "    #score_median = np.mean(np.abs(feature - np.median(feature)))\n",
    "    return score2, predicted\n",
    "\n",
    "def input_feature_assessment_classifier(cur, feature, clf):\n",
    "    #score = cross_val_score(clf, cur, feature, cv=20, scoring = \"neg_mean_absolute_error\")\n",
    "    \n",
    "    clf.fit(cur, feature)\n",
    "    predicted = clf.predict(cur)\n",
    "    score = clf.score(cur, feature)\n",
    "    #score_median = np.mean(np.abs(feature - np.median(feature)))\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: data to base x-axis meshgrid on\n",
    "    y: data to base y-axis meshgrid on\n",
    "    h: stepsize for meshgrid, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xx, yy : ndarray\n",
    "    \"\"\"\n",
    "    delta_x = (x.max() - x.min()) * 0.1\n",
    "    delta_y = (y.max() - y.min()) * 0.1\n",
    "    x_min, x_max = x.min() - delta_x, x.max() + delta_x\n",
    "    y_min, y_max = y.min() - delta_y, y.max() + delta_y\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axes object\n",
    "    clf: a classifier\n",
    "    xx: meshgrid ndarray\n",
    "    yy: meshgrid ndarray\n",
    "    params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sdf.s45___'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature_names = phenotype_df.columns.values\n",
    "np.array(feature_names)\n",
    "phenotype_df.columns.values\n",
    "import re\n",
    "re.sub(\"[^\\d^\\w^\\.]\", \"_\", \"sdf.s45+$<\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29L, 100000L)\n",
      "fluenzaverbale\n",
      "anova_ols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:06<00:00, 1501.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anova_f_oneway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:44<00:00, 2229.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:49<00:00, 2034.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:46<00:00, 2152.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:30<00:00, 3279.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:22<00:00, 1207.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\PC\\UNN\\Scientific\\Gerontology\\data\\GSE52588\\params\\num_cpgs_142987\\down_phenotypes\\regressions_fit_rand\\fluenzaverbale.pdf\n",
      "ABCletargia\n",
      "anova_ols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:03<00:00, 1580.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anova_f_oneway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:44<00:00, 2262.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:49<00:00, 2028.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:40<00:00, 2497.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:29<00:00, 3433.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:20<00:00, 1243.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\PC\\UNN\\Scientific\\Gerontology\\data\\GSE52588\\params\\num_cpgs_142987\\down_phenotypes\\regressions_fit_rand\\ABCletargia.pdf\n",
      "ABCstereotipie\n",
      "anova_ols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:02<00:00, 1599.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anova_f_oneway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:44<00:00, 2257.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:49<00:00, 2035.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:42<00:00, 2369.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:29<00:00, 3362.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:21<00:00, 1231.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\PC\\UNN\\Scientific\\Gerontology\\data\\GSE52588\\params\\num_cpgs_142987\\down_phenotypes\\regressions_fit_rand\\ABCstereotipie.pdf\n",
      "ABCinappropriatespeech\n",
      "anova_ols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:02<00:00, 1601.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anova_f_oneway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:44<00:00, 2269.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:49<00:00, 2035.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:42<00:00, 2342.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:29<00:00, 3405.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:20<00:00, 1246.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\PC\\UNN\\Scientific\\Gerontology\\data\\GSE52588\\params\\num_cpgs_142987\\down_phenotypes\\regressions_fit_rand\\ABCinappropriatespeech.pdf\n",
      "qiv\n",
      "anova_ols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:02<00:00, 1597.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anova_f_oneway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:44<00:00, 2265.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:48<00:00, 2042.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:39<00:00, 2556.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:28<00:00, 3550.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:20<00:00, 1238.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\PC\\UNN\\Scientific\\Gerontology\\data\\GSE52588\\params\\num_cpgs_142987\\down_phenotypes\\regressions_fit_rand\\qiv.pdf\n",
      "qip\n",
      "anova_ols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:02<00:00, 1607.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anova_f_oneway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:44<00:00, 2244.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:48<00:00, 2047.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:39<00:00, 2563.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:28<00:00, 3520.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:19<00:00, 1253.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\PC\\UNN\\Scientific\\Gerontology\\data\\GSE52588\\params\\num_cpgs_142987\\down_phenotypes\\regressions_fit_rand\\qip.pdf\n",
      "token\n",
      "anova_ols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:02<00:00, 1611.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anova_f_oneway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:44<00:00, 2272.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:48<00:00, 2049.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:39<00:00, 2517.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:28<00:00, 3531.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:20<00:00, 1244.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\PC\\UNN\\Scientific\\Gerontology\\data\\GSE52588\\params\\num_cpgs_142987\\down_phenotypes\\regressions_fit_rand\\token.pdf\n",
      "fluenzafonemica\n",
      "anova_ols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:02<00:00, 1608.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anova_f_oneway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:44<00:00, 2252.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:48<00:00, 2047.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:40<00:00, 2492.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:28<00:00, 3505.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:20<00:00, 1245.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\PC\\UNN\\Scientific\\Gerontology\\data\\GSE52588\\params\\num_cpgs_142987\\down_phenotypes\\regressions_fit_rand\\fluenzafonemica.pdf\n",
      "F.A.B.\n",
      "anova_ols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:02<00:00, 1609.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anova_f_oneway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:44<00:00, 2245.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:48<00:00, 2051.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:38<00:00, 2564.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:29<00:00, 3447.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:19<00:00, 1254.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\PC\\UNN\\Scientific\\Gerontology\\data\\GSE52588\\params\\num_cpgs_142987\\down_phenotypes\\regressions_fit_rand\\F.A.B..pdf\n",
      "ABCiperattivita\n",
      "anova_ols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:02<00:00, 1596.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anova_f_oneway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:44<00:00, 2253.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:49<00:00, 2039.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:43<00:00, 2323.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:29<00:00, 3382.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:20<00:00, 1249.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\PC\\UNN\\Scientific\\Gerontology\\data\\GSE52588\\params\\num_cpgs_142987\\down_phenotypes\\regressions_fit_rand\\ABCiperattivita.pdf\n",
      "ABCIrritabilita\n",
      "anova_ols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:02<00:00, 1603.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anova_f_oneway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:44<00:00, 2261.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:48<00:00, 2046.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:49<00:00, 2010.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:29<00:00, 3350.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:20<00:00, 1243.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\PC\\UNN\\Scientific\\Gerontology\\data\\GSE52588\\params\\num_cpgs_142987\\down_phenotypes\\regressions_fit_rand\\ABCIrritabilita.pdf\n",
      "DSQIID\n",
      "anova_ols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:02<00:00, 1602.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anova_f_oneway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:44<00:00, 2245.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:48<00:00, 2055.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:09<00:00, 1435.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [00:28<00:00, 3526.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [01:20<00:00, 1248.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\PC\\UNN\\Scientific\\Gerontology\\data\\GSE52588\\params\\num_cpgs_142987\\down_phenotypes\\regressions_fit_rand\\DSQIID.pdf\n"
     ]
    }
   ],
   "source": [
    "#data = parenclitics.drop(columns = [0,7,11,15,16,17,18])\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#data = parenclitics\n",
    "#data = data[:29].values\n",
    "XX = np.random.rand(X.shape[0], 100000)\n",
    "data = np.array(XX)\n",
    "#data = data[:, :100]\n",
    "data_full = stats.zscore(data)\n",
    "data = data_full[config.params[\"mongoloids_mask\"].value]\n",
    "print data.shape\n",
    "\n",
    "# Regression\n",
    "feature_names = [\"fluenzaverbale\", \"ABCletargia\", \"ABCstereotipie\", \"ABCinappropriatespeech\", \"qiv\", \"qip\", \"token\", \"fluenzafonemica\", \"F.A.B.\", \"ABCiperattivita\", \"ABCIrritabilita\", \"DSQIID\"]\n",
    "#feature_names = phenotype_df.columns.values\n",
    "clfs = [\"anova_ols\",\n",
    "        \"anova_f_oneway\",\n",
    "        linear_model.LinearRegression(),\n",
    "        svm.SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1),\n",
    "        #svm.SVR(kernel='poly', C=100, degree=3, epsilon=.1, coef0=1),\n",
    "        svm.LinearSVR(),\n",
    "        neighbors.KNeighborsRegressor(n_neighbors = 3),\n",
    "        #ensemble.RandomForestRegressor(n_estimators = 4),\n",
    "        #neural_network.MLPRegressor(max_iter = 50, hidden_layer_sizes = (10, ))\n",
    "        ]\n",
    "#clfs = [linear_model.LinearRegression()]\n",
    "# Classifiers\n",
    "'''\n",
    "feature_names = [\"categoriaDSQIID\", \"fluenzaverbale\",\"ABCiperattivita\", \"ABCIrritabilita\", \"ABCletargia\", \"ABCstereotipie\", \"ABCinappropriatespeech\", \"fluenzafonemica\", \"F.A.B.\"]\n",
    "clfs = [svm.SVC(kernel = 'rbf', C = 1, class_weight = \"balanced\"), \n",
    "        neighbors.KNeighborsClassifier(n_neighbors = 3),\n",
    "        svm.LinearSVC(C = 1, class_weight = \"balanced\"),\n",
    "        ensemble.RandomForestClassifier(n_estimators = 4),\n",
    "        neural_network.MLPClassifier(max_iter = 50, hidden_layer_sizes = (100, ))\n",
    "       ]\n",
    "'''\n",
    "is_normalized = False\n",
    "is_fit = True\n",
    "if not is_normalized:\n",
    "    data_full = np.array(XX)\n",
    "    norm_str = \"\"\n",
    "else:\n",
    "    norm_str = \"_norm\"\n",
    "\n",
    "if is_fit:\n",
    "    fit_str = \"_fit\"\n",
    "else:\n",
    "    fit_str = \"\"\n",
    "    \n",
    "np.set_printoptions(linewidth=100, formatter={'int':lambda x: \"{:2d}\".format(x), 'float':lambda x: \"{:.2f}\".format(x)})\n",
    "for feature_name in feature_names:\n",
    "    print feature_name\n",
    "    feature = (phenotype_df[feature_name].values)\n",
    "    feature_mask = ~np.isnan(feature)\n",
    "    cur = data[feature_mask]\n",
    "    feature = feature[~np.isnan(feature)].astype('int')\n",
    "    #print np.nan_to_num(phenotype_df[feature_name].values, 9).astype('int'), 'source'\n",
    "    #print feature, 'input', 'std =', \"{:.2f}\".format(np.std(feature)), 'iqr =', \"{:.2f}\".format(scipy.stats.iqr(feature, rng=(5, 95)) / 2)\n",
    "    model_names = []\n",
    "    fig, axes = plt.subplots(3, len(clfs), figsize = (len(clfs) * 5, 15))\n",
    "    fig.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "    fig.subplots_adjust(bottom=0.1, top=0.9, left=0.05, right=0.95)\n",
    "    for i, clf in enumerate(clfs):\n",
    "        scores = np.zeros((data.shape[1], ))\n",
    "        if type(clf) is str:\n",
    "            model_name = clf\n",
    "        else:\n",
    "            model_name = type(clf).__name__\n",
    "        print model_name\n",
    "        model_names.append(model_name)        \n",
    "\n",
    "        for j in tqdm(range(data.shape[1])):\n",
    "            scores[j], _ = input_feature_assessment_regr(cur[:, j].reshape(-1, 1), feature, clf)\n",
    "            \n",
    "        ids = np.argsort(scores) #[::-1]\n",
    "        #subset_scores = np.zeros((data.shape[0], ))\n",
    "        #print scores[ids[:len(subset_scores)]]\n",
    "        #for j in range(len(subset_scores)):\n",
    "        #    subset_scores[j], _ = input_feature_assessment_regr(cur[:, ids[:j + 1]], feature, clf)\n",
    "        #print subset_scores\n",
    "        #plt.plot(range(len(subset_scores)), subset_scores)\n",
    "        lines = [0] * 3\n",
    "        for j in range(3):\n",
    "            tid = ids[j]\n",
    "            ax = axes[j, i]\n",
    "            u, v = cur[:, tid], feature\n",
    "            \n",
    "            score, p = input_feature_assessment_regr(u.reshape(-1, 1), feature, clf)\n",
    "            u, v, p = u.flatten(), v.flatten(), p.flatten()\n",
    "            \n",
    "            #xx, yy = make_meshgrid(u, v)\n",
    "            #plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "            title_name = (model_name + '\\n' if j == 0 else '') + ' score = ' + \"{:0.2g}\".format(score)\n",
    "            plot_cpg_per_phenotype(data_full, v, p, tid, feature_mask, is_fit = is_fit, title_name = title_name)\n",
    "    #plt.show()\n",
    "    #break\n",
    "    \n",
    "    fig.suptitle(feature_name, fontsize = 2 * fontsize)\n",
    "    fig.legend(lines, ['Down', 'Siblings', 'Mothers'], framealpha=0.9, fontsize=30, #bbox_to_anchor=(0., 1.02, 1., .102), \n",
    "               loc=3,\n",
    "           ncol=3, mode=\"expand\", borderaxespad=0., handletextpad=0.3, scatterpoints=3)\n",
    "    \n",
    "    #plot_url = py.plot_mpl(fig)\n",
    "    \n",
    "    feature_name = re.sub(\"[^\\d^\\w^\\.]\", \"_\", feature_name)\n",
    "    regressions_path = config.ofname([[\"down_phenotypes\"], [\"regressions\" + fit_str + norm_str + \"_rand\"], [feature_name]], ext = \".pdf\", \n",
    "                                     include_set = config.params_sets[\"down_phenotypes\"])\n",
    "    print regressions_path\n",
    "    plt.savefig(regressions_path)\n",
    "    \n",
    "    regressions_path = config.ofname([[\"down_phenotypes\"], [\"regressions\" + fit_str + norm_str + \"_rand\"], [feature_name]], ext = \".png\", \n",
    "                                     include_set = config.params_sets[\"down_phenotypes\"])\n",
    "    plt.savefig(regressions_path)\n",
    "    \n",
    "    regressions_path = config.ofname([[\"down_phenotypes\"], [\"regressions\" + fit_str + norm_str + \"_rand\"], [feature_name]], ext = \".svg\", \n",
    "                                     include_set = config.params_sets[\"down_phenotypes\"])\n",
    "    plt.savefig(regressions_path)\n",
    "    \n",
    "    plt.close(fig)\n",
    "    #break\n",
    "    #break\n",
    "    #val = float(np.bincount(feature).max()) / len(feature)\n",
    "    #val = np.mean(np.abs(feature - np.median(feature)))\n",
    "    #plt.plot([0, len(subset_scores)], [val, val])\n",
    "        \n",
    "        #break\n",
    "    #plt.legend(model_names)\n",
    "    #plt.show()\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sdfdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-239-afb33d188432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mcid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcpgs_names\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0msdfdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sdfdf' is not defined"
     ]
    }
   ],
   "source": [
    "fontsize = 25\n",
    "fontname = \"Proxima Nova Rg\"\n",
    "\n",
    "def plot_cpg_per_phenotype(data_full, v, p, tid, feature_mask, is_fit = True, title_name = None, feature_name = None):\n",
    "    import scipy.stats as stats\n",
    "    u = data_full[config.params[\"mongoloids_mask\"].value, tid]\n",
    "    u = u[feature_mask]\n",
    "    if is_fit and len(p) > 0:\n",
    "        ids_x = np.argsort(u)\n",
    "        ax.plot(u[ids_x], p[ids_x], c = '#4285F4', linewidth = 3)\n",
    "    \n",
    "    lines[0] = ax.scatter(u, v, s = 80, c = '#EA4335', alpha = 0.8)\n",
    "    K = 4\n",
    "    x = data_full[:, tid]\n",
    "    \n",
    "    delta = x.ptp() * 0.01\n",
    "    x = np.linspace(x.min() - delta, x.max() + delta, 1000)\n",
    "    \n",
    "    delta_y = v.ptp() * 0.2\n",
    "    \n",
    "    density = stats.gaussian_kde(u)\n",
    "    y = density(x) / K\n",
    "    #ax.plot(x, y, c = '#EA4335')\n",
    "    #lines[2] = ax.fill_between(x, 0, y, color = '#EA4335',alpha=.3)\n",
    "    \n",
    "    u = data_full[config.params[\"siblings_mask\"].value, tid]\n",
    "    density = stats.gaussian_kde(u)\n",
    "    y = density(x) / K\n",
    "    #ax.plot(x, y, c = '#34A853')\n",
    "    #lines[1] = ax.fill_between(x, 0, y, color = '#34A853', alpha=.3)\n",
    "\n",
    "    #ax.hist(u, bins = np.linspace(u.min(), u.max(), 4), color = '#34A853', alpha = 0.5)\n",
    "    lines[1] = ax.scatter(u, -1 * delta_y + (np.random.rand(len(u), 1) - 0.5) * delta_y / 3, s = 80, c = '#34A853', alpha = 0.8)\n",
    "    u = data_full[config.params[\"mothers_mask\"].value, tid]\n",
    "    density = stats.gaussian_kde(u)\n",
    "    y = density(x) / K\n",
    "    #ax.plot(x, y, c = '#4285F4')\n",
    "    #lines[2] = ax.fill_between(x, 0, y, color = '#4285F4',alpha=.3)\n",
    "    #ax.hist(u, bins = np.linspace(u.min(), u.max(), 4), color = '#4285F4', alpha = 0.5)\n",
    "    lines[2] = ax.scatter(u, -2 * delta_y + (np.random.rand(len(u), 1) - 0.5) * delta_y / 3, s = 80, c = '#4285F4', alpha = 0.8)\n",
    "\n",
    "    if not title_name is None:\n",
    "        ax.set_title(title_name, fontsize = fontsize, fontname=fontname)\n",
    "    ax.set_xlabel(cpgs_names[tid], fontsize = fontsize, fontname=fontname)\n",
    "    if not feature_name is None:\n",
    "        ax.set_ylabel(feature_name, fontsize = fontsize, fontname=fontname)\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(4, steps = [1,2,3,4,5,6,7,8,9,10]))\n",
    "    plt.xticks(fontsize=fontsize, fontname=fontname)\n",
    "    plt.yticks(fontsize=fontsize, fontname=fontname)\n",
    "    #ax.set(xlim=(x.min(), x.max()), ylim = (0, None))\n",
    "    #ax.set_frame_on(True)\n",
    "\n",
    "def cpgname(name):\n",
    "    cid = np.nonzero(cpgs_names == name)\n",
    "    return cid[0][0]\n",
    "sdfdf\n",
    "\n",
    "data = np.array(X)\n",
    "data_full = stats.zscore(data)\n",
    "data = data_full[config.params[\"mongoloids_mask\"].value]\n",
    "\n",
    "data_full = np.array(X)\n",
    "\n",
    "feature_name = 'F.A.B.'\n",
    "model_name = ' '\n",
    "clf = clfs[2]\n",
    "tid = cpgname(\"cg00731253\") + 1\n",
    "\n",
    "\n",
    "feature_name = 'qip'\n",
    "model_name = 'SVR'\n",
    "clf = clfs[3]\n",
    "tid = cpgname(\"cg20180825\") + 1\n",
    "\n",
    "\n",
    "feature = (phenotype_df[feature_name].values)\n",
    "feature_mask = ~np.isnan(feature)\n",
    "cur = data[feature_mask]\n",
    "feature = feature[~np.isnan(feature)].astype('int')\n",
    "\n",
    "with plt.style.context(\"seaborn-whitegrid\"):\n",
    "    fig = plt.figure(figsize = (8, 6))\n",
    "    ax = plt.gca()\n",
    "    u, v = cur[:, tid], feature\n",
    "\n",
    "    _, p = input_feature_assessment_regr(u.reshape(-1, 1), feature, clf)\n",
    "    u, v, p = u.flatten(), v.flatten(), p.flatten()\n",
    "\n",
    "    #xx, yy = make_meshgrid(u, v)\n",
    "    #plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "\n",
    "    plot_cpg_per_phenotype(data_full, v, p, tid, feature_mask, is_fit = is_fit, feature_name = feature_name) #, title_name = model_name\n",
    "    #fig.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "    fig.subplots_adjust(bottom=0.3, top=0.95, left=0.15, right=0.95)\n",
    "    l = fig.legend(lines, [u'DS', u'Siblings', u'Mothers'], framealpha=0.9, fontsize=28, #bbox_to_anchor=(0., 1.02, 1., .102), \n",
    "                   loc=3,\n",
    "               ncol=3, mode=\"expand\", \n",
    "               borderaxespad=0, handletextpad=0.3, scatterpoints=3)\n",
    "    plt.setp(l.texts, family=fontname)\n",
    "    #plt.savefig('\\\\\\\\buddha\\In\\FAB_LR.png')\n",
    "    #plt.savefig('\\\\\\\\buddha\\In\\FAB_LR.svg', transparent=True)\n",
    "    \n",
    "    plt.savefig('\\\\\\\\buddha\\In\\qip_SVR.png')\n",
    "    plt.savefig('\\\\\\\\buddha\\In\\qip_SVR.svg', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29023 428614 cg01459453 cg25771195\n",
      "(87L, 2L)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGoCAYAAACwrGr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB0ngJIQQQgjhoP8HrwB4gLWeBFYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fontsize = 28\n",
    "fontname = \"Proxima Nova Rg\"\n",
    "\n",
    "def scater_down_syndrome(fig, ax, xu, xv, Y, gene_name_u, gene_name_v):\n",
    "    labels = ['DS', 'Siblings', 'Mothers']\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    ax.set_prop_cycle('color', [colors[0], colors[5], colors[1]])\n",
    "\n",
    "    for c in [0, 1, 2]:\n",
    "        ax.scatter(xu[Y == c], xv[Y == c], 200, label = labels[c], alpha=0.7)\n",
    "    \n",
    "    #for j in range(len(xu)):\n",
    "    #    ax.text(xu[j], xv[j], str(j), horizontalalignment='center', verticalalignment='center', fontsize = 15)\n",
    "\n",
    "    l = fig.legend(framealpha=0.9, fontsize=fontsize, loc=3, # bbox_to_anchor=(0., 1.02, 1., .102), \n",
    "           ncol=3, mode=\"expand\", borderaxespad=0., handletextpad=0.3, scatterpoints=3)    \n",
    "    plt.setp(l.texts, family=fontname)\n",
    "\n",
    "    \n",
    "    mean_p = []\n",
    "    for c in [0, 1, 2]:\n",
    "        mean_p.append([xu[Y == c].mean(), xv[Y == c].mean()])\n",
    "    for c in [0, 1]:\n",
    "        #plt.arrow(mean_p[2][0], mean_p[2][1], mean_p[c][0] - mean_p[2][0], mean_p[c][1] - mean_p[2][1], color = 'k')\n",
    "        ax.annotate(\"\", xy=(mean_p[c][0], mean_p[c][1]), xycoords='data', xytext=(mean_p[2][0], mean_p[2][1]),  textcoords='data', arrowprops=dict(shrink = 4,facecolor='black'), fontsize=20)\n",
    "\n",
    "    #k = (mean_p[0][1] - mean_p[2][1]) / (mean_p[0][0] - mean_p[2][0])\n",
    "    #if abs(k) > k_thr or abs(k) < 1.0 / k_thr:\n",
    "    #    continue\n",
    "    #s = \"k = {:0.2e}\".format(k)\n",
    "    #plt.text(0.17, 0.95, s, horizontalalignment='center', verticalalignment='center', transform = ax.transAxes, fontsize = 50)\n",
    "\n",
    "    ax.set_xlabel(gene_name_u, fontsize=fontsize, fontname = fontname)\n",
    "    ax.set_ylabel(gene_name_v, fontsize=fontsize, fontname = fontname)\n",
    "    fig.subplots_adjust(bottom=0.3, top=0.95, left=0.2, right=0.9)\n",
    "    plt.xticks(fontsize=25, fontname=fontname)\n",
    "    plt.yticks(fontsize=25, fontname=fontname)   \n",
    "    \n",
    "\n",
    "def genes_pair_plot(X, y, vertices, edges, genes_names):\n",
    "    #edges = np.concatenate((edges, np.array([edges[:, 1], edges[:, 0]]).T))\n",
    "    \n",
    "    import seaborn\n",
    "    #seaborn.set_style('darkgrid', {'legend.frameon':True})\n",
    "    seaborn.set_style('whitegrid')\n",
    "    \n",
    "    config.params[\"id_pair\"] = param(value_be = 0, value_en = len(edges) - 1, num_ticks = len(edges), name = 'id_pair', manual_ticks = True)\n",
    "    y = y.flatten()\n",
    "    pu = -1\n",
    "    k_thr = 3\n",
    "    \n",
    "    for i, e in enumerate(edges):\n",
    "        config.params[\"id_pair\"].set_tick(i)\n",
    "        fig = plt.figure(figsize=(8, 6))\n",
    "        ax = plt.gca()\n",
    "        #fig.set_visible(not fig.get_visible())\n",
    "        \n",
    "        \n",
    "        u = vertices[e[0]]\n",
    "        v = vertices[e[1]]\n",
    "        print u, v, genes_names[u], genes_names[v]\n",
    "        xu = X[:, u]\n",
    "        xv = X[:, v]\n",
    "        \n",
    "        #xu = (xu - xu.mean()) / xu.std()\n",
    "        #xv = (xv - xv.mean()) / xv.std()\n",
    "        \n",
    "        #mothers_mask = config.params[\"mothers_mask\"].value\n",
    "        #mongoloids_mask = config.params[\"mongoloids_mask\"].value\n",
    "        data = np.array([xu, xv]).astype('float32').T\n",
    "        print data.shape\n",
    "        \n",
    "        scater_down_syndrome(fig, ax, xu, xv, y, genes_names[u], genes_names[v])\n",
    "        #plt.ylim([0, 0.06])\n",
    "        #pair_genes_path = config.ofname([[\"kdes\", genes_names[u], genes_names[v]]], ext = \".png\", include_set = config.params_sets[\"kdes\"])\n",
    "        #print pair_genes_path\n",
    "        \n",
    "        file_name = \"\\\\\\\\buddha\\\\In\\\\\" + \"cpgs_\" + genes_names[u] + \"_\" + genes_names[v]\n",
    "        plt.savefig(file_name + \".svg\")\n",
    "        plt.savefig(file_name + \".png\")\n",
    "        break\n",
    "        #plt.close(fig)\n",
    "\n",
    "vertices = [cpgname(\"cg05365729\"), cpgname(\"cg04452713\"), cpgname(\"cg01459453\"), cpgname(\"cg25771195\")] #cg25809905 cg09809672 cg26372517\n",
    "edges = [[2, 3], [0, 1]]\n",
    "genes_pair_plot(X, y, vertices, edges, cpgs_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pair_genes_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-1e3847191714>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mprint\u001b[0m \u001b[0mpair_genes_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pair_genes_path' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7247499 1.4657556\n",
      "(25L,) (25L,)\n",
      "[False False False  True False False False False False False  True False  True False  True  True\n",
      " False False False False False False False False False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  1,  0,  0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cur[:, j].reshape(-1, 1)\n",
    "num_groups = 5\n",
    "bins = np.array(np.percentile(data, np.linspace(0, 100, num_groups + 1)))\n",
    "print data.min(), data.max()\n",
    "classes = np.minimum(np.digitize(data, bins), num_groups) - 1\n",
    "classes = classes.flatten()\n",
    "print feature.shape, classes.shape\n",
    "print classes == 0\n",
    "feature[classes == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\PC\\UNN\\Scientific\\Gerontology\\data\\GSE52588\\params\\num_genes_15024\\down_phenotypes\\regressions_fit.png\n"
     ]
    }
   ],
   "source": [
    "from configurations.config_down_GSE52588 import config\n",
    "regressions_path = config.ofname([[\"down_phenotypes\"], [\"regressions_fit\"]], ext = \".png\", \n",
    "                                 include_set = config.params_sets[\"down_phenotypes\"])\n",
    "print regressions_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29L, 1L) (29L,) (29L, 1L)\n",
      "[[ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]]\n",
      "(29L,)\n",
      "[0.24 -0.16 -0.68 -0.31 1.12 0.21 1.22 0.97 0.47 0.67 -0.09 1.23 0.35 0.99 1.52 -0.00 0.44 0.82 0.92\n",
      " 2.47 -0.19 1.27 0.48 1.17 0.82 1.28 0.07 0.23 0.49]\n",
      "[[0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]\n",
      " [0.24]]\n"
     ]
    }
   ],
   "source": [
    "print u.shape, v.shape, ids.shape\n",
    "print ids\n",
    "print p.shape\n",
    "print p\n",
    "print p.flatten()[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28L, 1L) (28L,)\n",
      "(28L, 2L) (28L,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.5357142857142856"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_feature_assessment(cur[:, ids[:1]], feature, clf)\n",
    "input_feature_assessment(cur[:, ids[:2]], feature, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 2'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:2d}\".format(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'brier_score_loss',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'mutual_info_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29L, 15024L)\n",
      "categoriaDSQIID\n",
      "[ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  0  1  0  0  1  0  0  0  0] good\n",
      "[ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  0  1  0  0  1  0  0  0  0] 0.76 0.79 1.00 SVC\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0] 0.68 0.79 0.86 KNeighborsClassifier\n",
      "[ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  0  1  0  0  1  0  0  0  0] 0.18 0.79 1.00 LinearSVC\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  0  1  0  0  1  0  0  0  0] 0.80 0.79 0.97 RandomForestClassifier\n",
      "fluenzaverbale\n",
      "[ 0  1  1  0  1  1  0  0  0  1  0  1  1  2  0  0  1  0  2  0  0  0  0  0  2] good\n",
      "[ 0  1  1  0  1  1  0  0  0  1  0  1  0  2  0  0  1  0  2  0  0  0  0  0  2] 0.65 0.56 0.96 SVC\n",
      "[ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  2] 0.48 0.56 0.68 KNeighborsClassifier\n",
      "[ 0  1  1  0  1  1  0  0  0  1  0  1  1  2  0  0  1  0  2  0  0  0  0  0  2] 0.13 0.56 1.00 LinearSVC\n",
      "[ 0  1  1  0  1  0  0  0  0  1  0  1  0  1  0  0  1  0  2  0  0  0  0  0  2] 0.53 0.56 0.88 RandomForestClassifier\n",
      "ABCiperattivita\n",
      "[ 5  0 12  1  0  0  3  2  9  1  0  3 43  2  2  2  0  2  0  0  1  1  0  0  2  0  0  2] good\n",
      "[ 5  2 12  1  0  0  3  2  9  1  2  3 43  2  2  2  2  2  2  2  1  1  2  2  2  0  2  2] 0.28 0.39 0.71 SVC\n",
      "[ 0  0  0  0  0  0  3  0  3  0  0  2  9  1  1  2  0  2  0  0  1  0  0  0  2  0  0  0] 0.42 0.39 0.57 KNeighborsClassifier\n",
      "[ 5  0 12  1  0  0  3  2  9  1  0  3 43  2  2  2  0  2  0  0  1  1  0  0  2  0  0  2] 0.05 0.39 1.00 LinearSVC\n",
      "[ 0  0 12  1  0  0  1  2  9  1  0  3 43  2  0  2  0  0  0  0  0  1  0  0  2  0  0  2] 0.32 0.39 0.82 RandomForestClassifier\n",
      "ABCIrritabilita\n",
      "[ 0  1  5  2  0  0  0  3  0  0  0  1  8 16  0  0  0  0  0  1  6  3  4  0  0  0  0  3] good\n",
      "[ 0  1  5  2  0  0  0  3  0  0  0  1  8 16  0  0  0  0  0  1  6  3  4  0  0  0  0  3] 0.37 0.57 1.00 SVC\n",
      "[ 0  0  1  0  0  0  0  0  0  0  0  1  0  6  0  0  0  0  0  1  6  1  0  0  0  0  0  0] 0.71 0.57 0.68 KNeighborsClassifier\n",
      "[ 0  1  5  2  0  0  0  3  0  0  0  1  8 16  0  0  0  0  0  1  6  3  4  0  0  0  0  3] 0.00 0.57 1.00 LinearSVC\n",
      "[ 0  1  5  2  0  0  0  3  0  0  0  1  8 16  0  0  0  0  0  1  0  3  4  0  0  0  0  0] 0.39 0.57 0.93 RandomForestClassifier\n",
      "ABCletargia\n",
      "[17  5  0  9 27  0  2  2 10 17  6 13  0  2 14  1  6 13  0 16  0 13  0  2  0  3  1  3] good\n",
      "[17  5  0  9 27  0  0  0 10 17  6 13  0  0 14  1  6  0  0 16  0 13  0  0  0  3  1  3] 0.25 0.25 0.82 SVC\n",
      "[ 5  5  0  0  0  0  2  2  2  6  6  2  0  0 14  1  6  1  0 13  0 13  0  0  0  3  1  3] 0.45 0.25 0.64 KNeighborsClassifier\n",
      "[17  5  0  9 27  0  2  2 10 17  6 13  0  2 14  1  6 13  0 16  0 13  0  2  0  3  1  3] 0.04 0.25 1.00 LinearSVC\n",
      "[17  5  5  9 27  0  2  2 10  2  6 13  0  2 14  1  6 13  0 16  0 13  0  2  0  0  0  3] 0.33 0.25 0.86 RandomForestClassifier\n",
      "ABCstereotipie\n",
      "[10  0  2  3 11  0  8  0  2  8  4  0  4  2  0  2  0  3  0  5  6  9  3  0  0  0  0  1] good\n",
      "[10  0  0  3 11  0  8  0  0  8  4  0  4  0  0  0  0  3  0  5  6  9  3  0  0  0  0  1] 0.51 0.39 0.86 SVC\n",
      "[ 0  0  0  0  0  0  2  0  2  4  4  0  2  2  0  2  0  2  0  5  4  5  0  0  0  0  0  0] 0.40 0.39 0.57 KNeighborsClassifier\n",
      "[10  0  2  3 11  0  8  0  2  8  4  0  4  2  0  2  0  3  0  5  6  9  3  0  0  0  0  1] 0.00 0.39 1.00 LinearSVC\n",
      "[10  0  2  3 11  0  8  0  2  8  4  0  4  2  0  2  0  3  0  5  0  0  3  0  0  0  0  0] 0.23 0.39 0.89 RandomForestClassifier\n",
      "ABCinappropriatespeech\n",
      "[ 2  4  2  3  6  0  2  2  4  5  4  3  9  5  0  2  7  3  5  0  3  3  5  1  1  3  4  6] good\n",
      "[ 2  4  2  3  6  0  2  2  4  5  4  3  9  5  0  2  7  5  5  0  3  3  5  1  1  3  4  6] 0.10 0.21 0.96 SVC\n",
      "[ 2  2  2  0  0  0  2  2  2  4  4  2  4  3  0  2  4  2  1  0  3  0  1  1  1  3  3  6] 0.19 0.21 0.50 KNeighborsClassifier\n",
      "[ 2  4  2  3  6  0  2  2  4  5  4  3  9  5  0  2  7  3  5  0  3  3  5  1  1  3  4  6] 0.03 0.21 1.00 LinearSVC\n",
      "[ 2  4  2  3  6  0  2  0  4  5  4  3  9  5  0  2  4  3  5  5  3  3  4  1  1  3  3  6] 0.07 0.21 0.82 RandomForestClassifier\n",
      "fluenzafonemica\n",
      "[ 0  9  3  8  3 19  9  6  0  5  7  2  9  0  0 14  0  8  0  7  3 20  0  6  9  0  6 20] good\n",
      "[ 0  9  3  8  3 19  9  6  0  5  7  2  9  0  0 14  0  8  0  7  3 20  0  6  6  0  6 20] 0.29 0.29 0.96 SVC\n",
      "[ 0  0  3  8  3  3  0  6  0  5  5  2  0  0  0  0  0  6  0  7  0  6  0  6  0  0  0 14] 0.22 0.29 0.57 KNeighborsClassifier\n",
      "[ 0  9  3  8  3 19  9  6  0  5  7  2  9  0  0 14  0  8  0  7  3 20  0  6  9  0  6 20] 0.00 0.29 1.00 LinearSVC\n",
      "[ 0  9  3  3  3  2  9  6  0  5  7  2  9  0  0 14  0  8  0  7  3 20  0  6  9  0  0  9] 0.18 0.29 0.86 RandomForestClassifier\n",
      "F.A.B.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from scipy import stats\n",
    "from sklearn import neighbors, ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "data = np.array(X)\n",
    "data = data[:29, :]\n",
    "print data.shape\n",
    "#data = data[:29].values\n",
    "data = stats.zscore(data)\n",
    "\n",
    "np.set_printoptions(linewidth=100, formatter={'int':lambda x: \"{:2d}\".format(x), 'float':lambda x: \"{:.2f}\".format(x)})\n",
    "feature_names = [\"categoriaDSQIID\", \"fluenzaverbale\",\"ABCiperattivita\", \"ABCIrritabilita\", \"ABCletargia\", \"ABCstereotipie\", \"ABCinappropriatespeech\", \"fluenzafonemica\", \"F.A.B.\"]\n",
    "for feature_name in feature_names:\n",
    "    print feature_name\n",
    "    feature = (phenotype_df[feature_name].values)\n",
    "    cur = data[~np.isnan(feature)]\n",
    "    feature = feature[~np.isnan(feature)].astype('int')\n",
    "    if (feature == 0).sum() < 3:\n",
    "        continue\n",
    "    \n",
    "    print feature, 'good'\n",
    "    clfs = [svm.SVC(kernel = 'rbf', C = 1, class_weight = \"balanced\"), \n",
    "            neighbors.KNeighborsClassifier(n_neighbors = 2),\n",
    "            svm.LinearSVC(C = 1, class_weight = \"balanced\"),\n",
    "            ensemble.RandomForestClassifier(n_estimators = 4)]\n",
    "\n",
    "    for clf in clfs:\n",
    "        score = cross_val_score(clf, cur, feature, cv=5).mean()\n",
    "        clf.fit(cur, feature)\n",
    "        predicted = clf.predict(cur)\n",
    "        score2 = clf.score(cur, feature)\n",
    "        val = float(np.bincount(feature).max()) / len(feature)\n",
    "        print predicted, \"{:.2f}\".format(score), \"{:.2f}\".format(val), \"{:.2f}\".format(score2), type(clf).__name__\n",
    "        \n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [01:40<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEBCAYAAABxK3LCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/T8aJcFNWX+66AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#py.sign_in('mike_live', 'rfHatoUPaLpzIMHQJKYK')\n",
    "\n",
    "plt.scatter(np.random.rand(10, 1), np.random.rand(10, 1))\n",
    "\n",
    "np.savez('tmp.npz', fig = plt.gcf())\n",
    "#plot_url = py.plot_mpl(plt.gcf())\n",
    "\n",
    "import pickle\n",
    "pickle.dump(plt.gcf(), open('FigureObject.fig.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'new_figure_manager_given_figure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-144549b50d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfigx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FigureObject.fig.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfigx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mike_live\\Anaconda2\\lib\\pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mike_live\\Anaconda2\\lib\\pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mike_live\\Anaconda2\\lib\\pickle.pyc\u001b[0m in \u001b[0;36mload_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0msetstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__setstate__\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msetstate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m             \u001b[0msetstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mslotstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\mike_live\\Anaconda2\\lib\\site-packages\\matplotlib\\figure.pyc\u001b[0m in \u001b[0;36m__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   1902\u001b[0m             \u001b[0mallnums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_fignums\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1903\u001b[0m             \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallnums\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallnums\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1904\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend_mod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_figure_manager_given_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1906\u001b[0m             \u001b[1;31m# XXX The following is a copy and paste from pyplot. Consider\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'new_figure_manager_given_figure'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "figx = pickle.load(open('FigureObject.fig.pickle', 'rb'))\n",
    "\n",
    "figx.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epimutations per phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categoriaDSQIID\n",
      "fluenzaverbale\n",
      "ABCiperattivita\n",
      "ABCIrritabilita\n",
      "ABCletargia\n",
      "ABCstereotipie\n",
      "ABCinappropriatespeech\n",
      "fluenzafonemica\n",
      "F.A.B.\n"
     ]
    }
   ],
   "source": [
    "def plot_per_phenotype(x, y, label_x = '', label_y = '', title = ''):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    ax = plt.axes()\n",
    "    ax.scatter(x, y, alpha = 0.5, linewidth = 3)\n",
    "    plt.xlabel(label_x, fontsize = fontsize)\n",
    "    plt.ylabel(label_y, fontsize = fontsize)\n",
    "    plt.title(title, fontsize = 1.2 * fontsize)\n",
    "    plt.subplots_adjust(bottom=0.2, top=0.9, left=0.2, right=0.95)\n",
    "    #plt.show()\n",
    "    \n",
    "def plot_per_phenotypes(new_feature, path_pdf, label = '', title = ''):\n",
    "    feature_names = [\"categoriaDSQIID\", \"fluenzaverbale\",\"ABCiperattivita\", \"ABCIrritabilita\", \"ABCletargia\", \"ABCstereotipie\", \"ABCinappropriatespeech\", \"fluenzafonemica\", \"F.A.B.\"]\n",
    "    #feature_names = phenotype_df.columns.values\n",
    "    from matplotlib.backends.backend_pdf import PdfPages\n",
    "    \n",
    "    with PdfPages(path_pdf) as pdf:\n",
    "        for feature_name in feature_names:\n",
    "            print (feature_name)\n",
    "            feature = (phenotype_df[feature_name].values)\n",
    "            cur = new_feature[~np.isnan(feature)]\n",
    "            feature = feature[~np.isnan(feature)].astype('int')\n",
    "            plot_per_phenotype(cur, feature, label_x = label, label_y = feature_name, title = title)\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "            \n",
    "\n",
    "df = pd.read_csv(config.ifname('epimutations'))\n",
    "path_pdf = config.ofname([[\"down_epimutations\"], [\"epimutation\", \"phenotypes\", \"small\"]], ext = \".pdf\", \n",
    "                                                 include_set = config.params_sets[\"down_epimutations\"])\n",
    "plot_per_phenotypes(df[\"epimutations_sum\"].values[:29], path_pdf, 'Number of epimutations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age per epimutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29,) (29,)\n",
      "[0.01427872]\n",
      "(29,) (29,)\n",
      "[-0.02116727]\n",
      "(29,) (29,)\n",
      "[0.01855536]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, RidgeCV, Lasso, ElasticNet\n",
    "groups = [\"mongoloids_mask\", \"siblings_mask\", \"mothers_mask\"]\n",
    "group_masks = [0] * 3\n",
    "for j, group_name in enumerate(groups):\n",
    "    group_masks[j] = config.params[group_name].value\n",
    "\n",
    "def plot_per_feature(x, y, group_masks, label_x = '', label_y = '', title = ''):\n",
    "    colors = ['r', 'g', 'b']\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    ax = plt.axes()\n",
    "    for j, mask in enumerate(group_masks):\n",
    "        cx = np.log(x[mask])\n",
    "        cy = y[mask]#.reshape(-1, 1)\n",
    "        print(cx.shape, cy.shape)\n",
    "        cy = cy[~np.isnan(cx)]\n",
    "        cx = cx[~np.isnan(cx)]\n",
    "        \n",
    "        cy = cy.reshape(-1, 1)\n",
    "        ax.scatter(cy, np.exp(cx), c = colors[j], alpha = 0.5, linewidth = 3)\n",
    "        model = LinearRegression().fit(cy, cx)\n",
    "        r_sq = model.score(cy, cx)\n",
    "        print(model.coef_)\n",
    "        ax.plot(cy, np.exp(model.predict(cy)), c = colors[j])\n",
    "        title += ' (' +  \"{:0.3f}\".format(r_sq) + ')'\n",
    "    \n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(label_y, fontsize = fontsize)\n",
    "    plt.ylabel(label_x, fontsize = fontsize)\n",
    "    plt.title(title, fontsize = 1.2 * fontsize)\n",
    "    plt.legend([\"Down\", \"Siblings\", \"Mothers\"])\n",
    "    plt.subplots_adjust(bottom=0.2, top=0.9, left=0.2, right=0.95)\n",
    "    #plt.show()            \n",
    "\n",
    "df = pd.read_csv(config.ifname('epimutations'))\n",
    "patients_info = pd.read_csv(config.ifname(\"patients_info\"), delimiter='\\t')\n",
    "age = patients_info[\"age\"].values\n",
    "epimutations_sum = df[\"epimutations_sum\"].values\n",
    "path_epimutations_age = config.ofname([[\"down_epimutations\"], [\"epimutation\", \"age\"]], ext = \".pdf\", \n",
    "                                                 include_set = config.params_sets[\"down_epimutations\"])\n",
    "epimutations_sum = epimutations_sum.astype('float')\n",
    "#epimutations_sum[epimutations_sum > 5000] = np.NaN\n",
    "plot_per_feature(epimutations_sum, age, group_masks, 'Number of epimutations', 'Age')\n",
    "plt.savefig(path_epimutations_age)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parenclitic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]), array([29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
      "       46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57]), array([58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74,\n",
      "       75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86]), array([ 87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
      "       100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "       113, 114, 115])]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "groups = [\"mongoloids_mask\", \"siblings_mask\", \"mothers_mask\", \"random_mask\"]\n",
    "config.params[\"random_mask\"] = param(np.arange(29 * 3, 29 * 4), name = 'random_mask')\n",
    "group_masks = [0] * 4\n",
    "for j, group_name in enumerate(groups):\n",
    "    group_masks[j] = config.params[group_name].value\n",
    "Y = np.concatenate([y, np.ones((29, )) * 3])\n",
    "print(group_masks)\n",
    "print(Y)\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from matplotlib import gridspec\n",
    "#plt.boxplot([epimutations[y == 0], epimutations[y == 1], epimutations[y == 2]])\n",
    "def plot_parenclitic(parenclitic, groups, y, title, x_label, is_xlog, is_ylog, is_cdf, is_kde):\n",
    "    colors = ['r', 'g', 'b', 'm']\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1]) \n",
    "\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    ax1 = plt.subplot(gs[1], sharex = ax0)\n",
    "    \n",
    "    yy = [[],[],[],[]]\n",
    "    xx = [0] * 4\n",
    "    zeros = [0] * 4\n",
    "    for j in range(len(groups)):\n",
    "        #print(groups[j])\n",
    "        #mn = [print(\"{:0.2g}\".format(np.min(w[w > 1e-7])), end=' ') for w in parenclitic[y == j].values]\n",
    "        #print()\n",
    "        #print(mn)\n",
    "        x = parenclitic[y == j].values\n",
    "        \n",
    "        if len(x.shape) > 1:\n",
    "            x = np.concatenate(x)\n",
    "        \n",
    "        is_small = x.std() < 1e-9\n",
    "        #plt.hist(x, bins  = 100, color = colors[j], alpha = 0.5, histtype = 'step')\n",
    "        zero_mask = (x < 0)\n",
    "        zeros[j] = zero_mask.sum()\n",
    "        x = x[~zero_mask]\n",
    "        xx[j] = x\n",
    "        #if j == 0:\n",
    "        #    continue\n",
    "        #x = x / xx[0]\n",
    "        #x = x[~np.isnan(x) & ~np.isinf(x)]\n",
    "        xx[j] = x\n",
    "        mn = np.min(x)\n",
    "        mx = np.max(x)\n",
    "        if is_cdf:\n",
    "            numbins = 100\n",
    "        else:\n",
    "            numbins = 30\n",
    "                \n",
    "        if is_xlog:\n",
    "            bins = np.logspace(np.log10(mn), np.log10(mx), numbins)\n",
    "            x = x[x > 0]\n",
    "        else:\n",
    "            bins = np.linspace(mn, mx, numbins)\n",
    "            \n",
    "            \n",
    "        if is_cdf:\n",
    "            ecdf = ECDF(x)\n",
    "            ax0.plot(bins, ecdf(bins), c = colors[j])\n",
    "        elif is_kde:\n",
    "            x = x[~np.isnan(x) & ~np.isinf(x)]\n",
    "            if j < 3 and not is_small and len(np.unique(x)) > 1:\n",
    "                if is_xlog:\n",
    "                    kde = stats.gaussian_kde(np.log10(x))\n",
    "                    kde_y = kde(np.log10(bins))\n",
    "                else:\n",
    "                    kde = stats.gaussian_kde(x)\n",
    "                    kde_y = kde(bins)\n",
    "                ax0.plot(bins, kde_y, colors[j], alpha = 0.5, linewidth = 3)\n",
    "            else:\n",
    "                ax0.plot([bins[0], bins[0]], [0, 0], colors[j], alpha = 0.5, linewidth = 3)\n",
    "            #my = max(kde_y)\n",
    "            #dy = my * 0.025\n",
    "            #yy = -np.random.rand(x.shape[0]) * dy * 0.8 - 2.5 * dy * j - dy\n",
    "            yy[j] = np.random.rand(x.shape[0]) * 0.8 + 2.5 * j\n",
    "            ax1.scatter(x, yy[j], c = colors[j], alpha = 0.5, s = 30)\n",
    "        else:\n",
    "            if not is_small:\n",
    "                cnt, xx = np.histogram(x, bins = bins)\n",
    "                ax0.plot(xx[:-1], cnt, c = colors[j])\n",
    "        \n",
    "    #ax0.plot([1, 1], ax0.get_ylim(), 'r')\n",
    "    #ax1.plot([1, 1], [0, 3], 'r')\n",
    "    cnt_change = [0, 0, 0]\n",
    "    eps = 0 #np.concatenate(xx).ptp() / 100\n",
    "    '''\n",
    "    for i in range(len(xx[0])):\n",
    "        ax1.plot([xx[0][i], xx[1][i]], [yy[0][i], yy[1][i]])\n",
    "        if xx[0][i] - xx[1][i] > eps:\n",
    "            cnt_change[0] += 1\n",
    "        elif xx[0][i] - xx[1][i] < -eps:\n",
    "            cnt_change[2] += 1\n",
    "        else:\n",
    "            cnt_change[1] += 1\n",
    "        #ax1.plot([xx[2][i], xx[1][i]], [yy[2][i], yy[1][i]])\n",
    "        #ax1.plot([xx[2][i], xx[0][i]], [yy[2][i], yy[0][i]])\n",
    "    '''\n",
    "    #plt.xlim(left = 0)\n",
    "    \n",
    "    #ax0.ticklabel_format(scilimits = [-2, 2])\n",
    "    ax1.ticklabel_format(scilimits = [-2, 2])\n",
    "    if is_xlog:\n",
    "        ax0.set_xscale('log')\n",
    "    else:\n",
    "        ax0.ticklabel_format(scilimits = [-2, 2], axis = 'x')\n",
    "    \n",
    "    if is_ylog:\n",
    "        ax0.set_yscale('log')\n",
    "    else:\n",
    "        ax0.ticklabel_format(scilimits = [-2, 2], axis = 'y')\n",
    "    ax0.legend([\"Down\", # + \" (Zeros = \" + str(zeros[0]) + \")\", \\\n",
    "                \"Siblings\", # + \" (Zeros = \" + str(zeros[1]) + \")\", \\\n",
    "                \"Mothers\", # + \" (Zeros = \" + str(zeros[2]) + \")\", \\\n",
    "                \"Random SVC\", # + \" (Zeros = \" + str(zeros[3]) + \")\", \\\n",
    "               ], fontsize = 0.5 * fontsize)\n",
    "    \n",
    "    plt.setp(ax0.get_xticklabels(), visible=False)\n",
    "    plt.setp(ax1.get_yticklabels(), visible=False)\n",
    "    \n",
    "    ax1.grid(True, axis = 'x')\n",
    "    ax1.grid(False, axis = 'y')\n",
    "\n",
    "    # Hide axes ticks\n",
    "    #ax1.set_yticks([])\n",
    "    \n",
    "    ax1.set_xlabel(x_label, fontsize = fontsize)\n",
    "    ax0.set_ylabel('${\\\\bf PDF}$', fontsize = fontsize)\n",
    "    ax0.set_title(title, fontsize = 1.2 * fontsize)  #  + \" \" + str(cnt_change)\n",
    "    plt.subplots_adjust(bottom=0.2, top=0.9, left=0.2, right=0.95, hspace=.02)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\PC\\UNN\\Science\\Gerontology\\data\\GSE52588\\params\\num_genes_14756\\kde_mask_siblings_mask\\algorithm_pdf\\thr_type_best\\parenclitic_distributions_xlog___kde.pdf\n",
      "Zeros betweenness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: RuntimeWarning: divide by zero encountered in log10\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\function_base.py:159: RuntimeWarning: invalid value encountered in multiply\n",
      "  y *= step\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\function_base.py:168: RuntimeWarning: invalid value encountered in add\n",
      "  y += start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max betweenness\n",
      "Min betweenness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\function_base.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  delta = stop - start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean betweenness\n",
      "Std betweenness\n",
      "Zeros pagerank\n",
      "Max pagerank\n",
      "Min pagerank\n",
      "Mean pagerank\n",
      "Std pagerank\n",
      "Zeros closeness\n",
      "Max closeness\n",
      "Min closeness\n",
      "Mean closeness\n",
      "Std closeness\n",
      "Zeros eigenvector centrality\n",
      "Max eigenvector centrality\n",
      "Min eigenvector centrality\n",
      "Mean eigenvector centrality\n",
      "Std eigenvector centrality\n",
      "Zeros degrees\n",
      "Max degrees\n",
      "Min degrees\n",
      "Mean degrees\n",
      "Std degrees\n",
      "Number of edges\n",
      "Number of nodes\n",
      "Max component size\n",
      "Max component size norm nodes\n",
      "Max component size norm edges\n",
      "Efficiency\n",
      "Robustness\n"
     ]
    }
   ],
   "source": [
    "is_ylog = False\n",
    "is_xlog = True\n",
    "is_cdf = False\n",
    "is_kde = True\n",
    "parenclitic_pairs_path = config.ofname([[\"parenclitic_distributions\", # _inside\n",
    "                                        \"xlog\" if is_xlog else \"\", \\\n",
    "                                        \"ylog\" if is_ylog else \"\", \\\n",
    "                                        \"cdf\" if is_cdf else \"\",\n",
    "                                        \"kde\" if is_kde else \"\"]], ext = \".pdf\", \\\n",
    "                                     include_set = config.params_sets[\"parenclitic_boxplots\"])\n",
    "print(parenclitic_pairs_path)\n",
    "with PdfPages(parenclitic_pairs_path) as pdf:\n",
    "    for i in parenclitics:\n",
    "        print(parenclitic_names[i])\n",
    "        if np.std(parenclitics[i]) < 1e-8:\n",
    "            continue\n",
    "        plot_parenclitic(parenclitics[i], groups, Y, parenclitic_names[i], parenclitic_names[i], is_xlog, is_ylog, is_cdf, is_kde)\n",
    "        pdf.savefig(dpi = 300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.int64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-40c2754439ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparenclitic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparenclitics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparenclitic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#len(np.concatenate(parenclitic[y == 0].values))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
     ]
    }
   ],
   "source": [
    "parenclitic = parenclitics[0]\n",
    "len(parenclitic[0])\n",
    "#len(np.concatenate(parenclitic[y == 0].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parenclitics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\"mongoloids_mask\", \"siblings_mask\", \"mothers_mask\"]\n",
    "group_masks = [0] * 3\n",
    "for j, group_name in enumerate(groups):\n",
    "    group_masks[j] = config.params[group_name].value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get DS parenclitics only\n",
    "real_data_mask = range(29 * 3)\n",
    "data = parenclitics.values[real_data_mask]\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(data)  \n",
    "Xt = pca.transform(data)\n",
    "\n",
    "colors = ['red', 'green', 'blue']\n",
    "\n",
    "for j in range(3):\n",
    "    plt.scatter(Xt[group_masks[j], 2], Xt[group_masks[j], 5], c = colors[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 AdaBoostClassifier\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 BaggingClassifier\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 BernoulliNB\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 CalibratedClassifierCV\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 ComplementNB\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 DecisionTreeClassifier\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 0.99 0.67 1.00 ExtraTreeClassifier\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 ExtraTreesClassifier\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 GaussianNB\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 0.33 0.67 1.00 GaussianProcessClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 GradientBoostingClassifier\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 0.99 0.67 0.99 KNeighborsClassifier\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 0.33 0.67 1.00 LabelPropagation\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 0.33 0.67 1.00 LabelSpreading\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 LinearDiscriminantAnalysis\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 LinearSVC\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\semi_supervised\\label_propagation.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 LogisticRegressionCV\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0] 0.81 0.67 0.33 MLPClassifier\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 MultinomialNB\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 1 1] 0.85 0.67 0.85 NearestCentroid\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 0.67 0.67 1.00 NuSVC\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 PassiveAggressiveClassifier\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 0.98 0.67 1.00 Perceptron\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 QuadraticDiscriminantAnalysis\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number3.264970e-17\n",
      "  overwrite_a=True).T\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number2.997973e-17\n",
      "  overwrite_a=True).T\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number3.378425e-17\n",
      "  overwrite_a=True).T\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number4.014177e-17\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 RidgeClassifier\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 0.75 0.67 1.00 RidgeClassifierCV\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 1.00 0.67 1.00 SGDClassifier\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1] 0.67 0.67 1.00 SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number3.239407e-17\n",
      "  overwrite_a=True).T\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: scipy.linalg.solve\n",
      "Ill-conditioned matrix detected. Result is not guaranteed to be accurate.\n",
      "Reciprocal condition number2.709358e-17\n",
      "  overwrite_a=True).T\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.utils.testing import all_estimators\n",
    "classifiers=[est for est in all_estimators() if issubclass(est[1], ClassifierMixin)]\n",
    "#print(classifiers)\n",
    "\n",
    "clfs = [svm.SVC(kernel = 'rbf', C = 1, class_weight = \"balanced\", gamma = 'auto'), \n",
    "            neighbors.KNeighborsClassifier(n_neighbors = 2),\n",
    "            svm.LinearSVC(C = 1, class_weight = \"balanced\"),\n",
    "            ensemble.RandomForestClassifier(n_estimators = 4)]\n",
    "Y = (y > 0).astype('uint8')\n",
    "for clf in classifiers:\n",
    "    clf = clf[1]()\n",
    "    try:\n",
    "        score = cross_val_score(clf, data, Y, cv=5).mean()\n",
    "        clf.fit(data, Y)\n",
    "        predicted = clf.predict(data)\n",
    "        score2 = clf.score(data, Y)\n",
    "        val = float(np.bincount(Y).max()) / len(Y)\n",
    "        print (predicted, \"{:.2f}\".format(score), \"{:.2f}\".format(val), \"{:.2f}\".format(score2), type(clf).__name__)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5784</td>\n",
       "      <td>1.919681e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>4793.972825</td>\n",
       "      <td>240661.980998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031190</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>30.865140</td>\n",
       "      <td>193.585539</td>\n",
       "      <td>227723</td>\n",
       "      <td>14756</td>\n",
       "      <td>11649</td>\n",
       "      <td>0.789442</td>\n",
       "      <td>0.051154</td>\n",
       "      <td>0.348444</td>\n",
       "      <td>1733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6794</td>\n",
       "      <td>3.178820e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5218.149024</td>\n",
       "      <td>311968.162671</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052891</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23.456899</td>\n",
       "      <td>194.776024</td>\n",
       "      <td>173065</td>\n",
       "      <td>14756</td>\n",
       "      <td>12369</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.071470</td>\n",
       "      <td>0.396730</td>\n",
       "      <td>1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3145</td>\n",
       "      <td>3.008115e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>6449.089184</td>\n",
       "      <td>271046.371279</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>178.899837</td>\n",
       "      <td>463.849655</td>\n",
       "      <td>1319923</td>\n",
       "      <td>14756</td>\n",
       "      <td>13866</td>\n",
       "      <td>0.939686</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>0.505752</td>\n",
       "      <td>3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7103</td>\n",
       "      <td>2.819635e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>4711.488411</td>\n",
       "      <td>324698.997066</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063424</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>14.067362</td>\n",
       "      <td>149.268327</td>\n",
       "      <td>103789</td>\n",
       "      <td>14756</td>\n",
       "      <td>11618</td>\n",
       "      <td>0.787341</td>\n",
       "      <td>0.111939</td>\n",
       "      <td>0.346997</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5103</td>\n",
       "      <td>2.206385e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>4751.740241</td>\n",
       "      <td>214261.707832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025997</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>47.044728</td>\n",
       "      <td>208.237730</td>\n",
       "      <td>347096</td>\n",
       "      <td>14756</td>\n",
       "      <td>11432</td>\n",
       "      <td>0.774736</td>\n",
       "      <td>0.032936</td>\n",
       "      <td>0.332817</td>\n",
       "      <td>2112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6709</td>\n",
       "      <td>3.081925e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>4355.848333</td>\n",
       "      <td>274532.883561</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063441</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.148008</td>\n",
       "      <td>133.300700</td>\n",
       "      <td>97006</td>\n",
       "      <td>14756</td>\n",
       "      <td>10861</td>\n",
       "      <td>0.736040</td>\n",
       "      <td>0.111962</td>\n",
       "      <td>0.297630</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9373</td>\n",
       "      <td>4.384667e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>6580.887436</td>\n",
       "      <td>511810.575646</td>\n",
       "      <td>0</td>\n",
       "      <td>0.106310</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.064381</td>\n",
       "      <td>173.156916</td>\n",
       "      <td>74255</td>\n",
       "      <td>14756</td>\n",
       "      <td>13935</td>\n",
       "      <td>0.944362</td>\n",
       "      <td>0.187664</td>\n",
       "      <td>0.499722</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7470</td>\n",
       "      <td>2.090158e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>4203.179385</td>\n",
       "      <td>208935.551557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051416</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12.307943</td>\n",
       "      <td>125.001291</td>\n",
       "      <td>90808</td>\n",
       "      <td>14756</td>\n",
       "      <td>10302</td>\n",
       "      <td>0.698157</td>\n",
       "      <td>0.113448</td>\n",
       "      <td>0.260771</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8761</td>\n",
       "      <td>5.882291e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5273.566481</td>\n",
       "      <td>493581.508209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121513</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.539848</td>\n",
       "      <td>133.331617</td>\n",
       "      <td>70385</td>\n",
       "      <td>14756</td>\n",
       "      <td>12463</td>\n",
       "      <td>0.844606</td>\n",
       "      <td>0.177069</td>\n",
       "      <td>0.401404</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3652</td>\n",
       "      <td>2.520365e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5984.770670</td>\n",
       "      <td>344248.997834</td>\n",
       "      <td>0</td>\n",
       "      <td>0.079699</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.989157</td>\n",
       "      <td>213.964344</td>\n",
       "      <td>81078</td>\n",
       "      <td>14756</td>\n",
       "      <td>13279</td>\n",
       "      <td>0.899905</td>\n",
       "      <td>0.163781</td>\n",
       "      <td>0.456437</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5217</td>\n",
       "      <td>3.207252e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5411.318786</td>\n",
       "      <td>315824.945159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065111</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16.104906</td>\n",
       "      <td>200.336599</td>\n",
       "      <td>118822</td>\n",
       "      <td>14756</td>\n",
       "      <td>12609</td>\n",
       "      <td>0.854500</td>\n",
       "      <td>0.106117</td>\n",
       "      <td>0.412319</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6070</td>\n",
       "      <td>4.826322e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5541.303470</td>\n",
       "      <td>416815.106761</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087928</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.376931</td>\n",
       "      <td>170.081898</td>\n",
       "      <td>98695</td>\n",
       "      <td>14756</td>\n",
       "      <td>12777</td>\n",
       "      <td>0.865885</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.422868</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4676</td>\n",
       "      <td>8.059084e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>4944.723367</td>\n",
       "      <td>94101.990454</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008376</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>76.999458</td>\n",
       "      <td>237.035602</td>\n",
       "      <td>568102</td>\n",
       "      <td>14756</td>\n",
       "      <td>11024</td>\n",
       "      <td>0.747086</td>\n",
       "      <td>0.019405</td>\n",
       "      <td>0.297434</td>\n",
       "      <td>2745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3107</td>\n",
       "      <td>1.970367e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5390.699648</td>\n",
       "      <td>256693.737679</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029068</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42.116698</td>\n",
       "      <td>240.623195</td>\n",
       "      <td>310737</td>\n",
       "      <td>14756</td>\n",
       "      <td>12509</td>\n",
       "      <td>0.847723</td>\n",
       "      <td>0.040256</td>\n",
       "      <td>0.405311</td>\n",
       "      <td>2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5250</td>\n",
       "      <td>2.364352e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5621.956425</td>\n",
       "      <td>309248.862247</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044284</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>25.336677</td>\n",
       "      <td>219.535780</td>\n",
       "      <td>186934</td>\n",
       "      <td>14756</td>\n",
       "      <td>12862</td>\n",
       "      <td>0.871645</td>\n",
       "      <td>0.068805</td>\n",
       "      <td>0.429259</td>\n",
       "      <td>1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6056</td>\n",
       "      <td>3.913562e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5685.302657</td>\n",
       "      <td>360956.476087</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081263</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.258607</td>\n",
       "      <td>204.414478</td>\n",
       "      <td>97822</td>\n",
       "      <td>14756</td>\n",
       "      <td>12949</td>\n",
       "      <td>0.877541</td>\n",
       "      <td>0.132373</td>\n",
       "      <td>0.434797</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8092</td>\n",
       "      <td>2.063759e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>3938.772160</td>\n",
       "      <td>209749.675163</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061286</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.783410</td>\n",
       "      <td>98.046945</td>\n",
       "      <td>64804</td>\n",
       "      <td>14756</td>\n",
       "      <td>9704</td>\n",
       "      <td>0.657631</td>\n",
       "      <td>0.149744</td>\n",
       "      <td>0.226128</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3078</td>\n",
       "      <td>2.678981e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5724.722960</td>\n",
       "      <td>341169.802640</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086848</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.859718</td>\n",
       "      <td>199.706977</td>\n",
       "      <td>72745</td>\n",
       "      <td>14756</td>\n",
       "      <td>12969</td>\n",
       "      <td>0.878897</td>\n",
       "      <td>0.178280</td>\n",
       "      <td>0.434931</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7440</td>\n",
       "      <td>3.990279e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>4246.773719</td>\n",
       "      <td>331077.317437</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074181</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12.451477</td>\n",
       "      <td>113.172913</td>\n",
       "      <td>91867</td>\n",
       "      <td>14756</td>\n",
       "      <td>10663</td>\n",
       "      <td>0.722621</td>\n",
       "      <td>0.116070</td>\n",
       "      <td>0.285318</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7955</td>\n",
       "      <td>2.897846e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5095.622052</td>\n",
       "      <td>328978.916090</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069540</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.391027</td>\n",
       "      <td>171.046967</td>\n",
       "      <td>98799</td>\n",
       "      <td>14756</td>\n",
       "      <td>12197</td>\n",
       "      <td>0.826579</td>\n",
       "      <td>0.123453</td>\n",
       "      <td>0.384803</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6434</td>\n",
       "      <td>2.895810e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>6088.712930</td>\n",
       "      <td>343894.919309</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046534</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>29.243969</td>\n",
       "      <td>225.938628</td>\n",
       "      <td>215762</td>\n",
       "      <td>14756</td>\n",
       "      <td>13408</td>\n",
       "      <td>0.908647</td>\n",
       "      <td>0.062143</td>\n",
       "      <td>0.466542</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4800</td>\n",
       "      <td>2.231146e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5085.328815</td>\n",
       "      <td>237447.362271</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040080</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>26.309027</td>\n",
       "      <td>225.905555</td>\n",
       "      <td>194108</td>\n",
       "      <td>14756</td>\n",
       "      <td>12148</td>\n",
       "      <td>0.823258</td>\n",
       "      <td>0.062584</td>\n",
       "      <td>0.382035</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6105</td>\n",
       "      <td>2.314741e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5139.665424</td>\n",
       "      <td>266173.380854</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048682</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19.636758</td>\n",
       "      <td>206.983531</td>\n",
       "      <td>144880</td>\n",
       "      <td>14756</td>\n",
       "      <td>12224</td>\n",
       "      <td>0.828409</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.386618</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5752</td>\n",
       "      <td>3.143332e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5994.125644</td>\n",
       "      <td>346376.935818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065157</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16.975197</td>\n",
       "      <td>216.325576</td>\n",
       "      <td>125243</td>\n",
       "      <td>14756</td>\n",
       "      <td>13301</td>\n",
       "      <td>0.901396</td>\n",
       "      <td>0.106202</td>\n",
       "      <td>0.458919</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9251</td>\n",
       "      <td>4.503658e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5621.641027</td>\n",
       "      <td>416510.079161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.109054</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.155191</td>\n",
       "      <td>166.639584</td>\n",
       "      <td>67547</td>\n",
       "      <td>14756</td>\n",
       "      <td>12872</td>\n",
       "      <td>0.872323</td>\n",
       "      <td>0.190564</td>\n",
       "      <td>0.428968</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6430</td>\n",
       "      <td>3.447845e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>6037.910613</td>\n",
       "      <td>404218.838125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059055</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>21.420575</td>\n",
       "      <td>199.120938</td>\n",
       "      <td>158041</td>\n",
       "      <td>14756</td>\n",
       "      <td>13350</td>\n",
       "      <td>0.904717</td>\n",
       "      <td>0.084472</td>\n",
       "      <td>0.461498</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3865</td>\n",
       "      <td>3.907966e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>5371.511182</td>\n",
       "      <td>71638.215867</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>121.835728</td>\n",
       "      <td>346.688031</td>\n",
       "      <td>898904</td>\n",
       "      <td>14756</td>\n",
       "      <td>11771</td>\n",
       "      <td>0.797709</td>\n",
       "      <td>0.013095</td>\n",
       "      <td>0.346845</td>\n",
       "      <td>3224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6704</td>\n",
       "      <td>3.533555e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>4683.371849</td>\n",
       "      <td>312530.480583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068542</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>14.412442</td>\n",
       "      <td>152.452333</td>\n",
       "      <td>106335</td>\n",
       "      <td>14756</td>\n",
       "      <td>11532</td>\n",
       "      <td>0.781513</td>\n",
       "      <td>0.108450</td>\n",
       "      <td>0.340968</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4450</td>\n",
       "      <td>2.141574e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5571.240445</td>\n",
       "      <td>241979.188406</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032462</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>39.203985</td>\n",
       "      <td>274.203368</td>\n",
       "      <td>289247</td>\n",
       "      <td>14756</td>\n",
       "      <td>12785</td>\n",
       "      <td>0.866427</td>\n",
       "      <td>0.044201</td>\n",
       "      <td>0.424914</td>\n",
       "      <td>1541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6100</td>\n",
       "      <td>2.572861e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>4728.525617</td>\n",
       "      <td>260641.138066</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046892</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>21.135538</td>\n",
       "      <td>182.063113</td>\n",
       "      <td>155938</td>\n",
       "      <td>14756</td>\n",
       "      <td>11601</td>\n",
       "      <td>0.786189</td>\n",
       "      <td>0.074395</td>\n",
       "      <td>0.345848</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2909</td>\n",
       "      <td>1.618914e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>6215.537815</td>\n",
       "      <td>269015.077559</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034481</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>30.705340</td>\n",
       "      <td>288.000768</td>\n",
       "      <td>226544</td>\n",
       "      <td>14756</td>\n",
       "      <td>13526</td>\n",
       "      <td>0.916644</td>\n",
       "      <td>0.059706</td>\n",
       "      <td>0.474667</td>\n",
       "      <td>1067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>5446</td>\n",
       "      <td>4.940079e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5699.822581</td>\n",
       "      <td>410522.644652</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054014</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23.879642</td>\n",
       "      <td>148.624134</td>\n",
       "      <td>176184</td>\n",
       "      <td>14756</td>\n",
       "      <td>12430</td>\n",
       "      <td>0.842369</td>\n",
       "      <td>0.070551</td>\n",
       "      <td>0.389794</td>\n",
       "      <td>1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5194</td>\n",
       "      <td>5.372219e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6124.862022</td>\n",
       "      <td>108304.975097</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011246</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23.615885</td>\n",
       "      <td>119.874611</td>\n",
       "      <td>174238</td>\n",
       "      <td>14756</td>\n",
       "      <td>11193</td>\n",
       "      <td>0.758539</td>\n",
       "      <td>0.064240</td>\n",
       "      <td>0.279458</td>\n",
       "      <td>1512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5552</td>\n",
       "      <td>1.155857e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5856.485633</td>\n",
       "      <td>136609.612447</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019519</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20.619545</td>\n",
       "      <td>114.972961</td>\n",
       "      <td>152131</td>\n",
       "      <td>14756</td>\n",
       "      <td>11041</td>\n",
       "      <td>0.748238</td>\n",
       "      <td>0.072576</td>\n",
       "      <td>0.274417</td>\n",
       "      <td>1517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5284</td>\n",
       "      <td>1.143807e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>6060.939076</td>\n",
       "      <td>145334.394664</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017926</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>24.962998</td>\n",
       "      <td>129.115220</td>\n",
       "      <td>184177</td>\n",
       "      <td>14756</td>\n",
       "      <td>11379</td>\n",
       "      <td>0.771144</td>\n",
       "      <td>0.061783</td>\n",
       "      <td>0.295389</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5135</td>\n",
       "      <td>7.660071e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6014.238208</td>\n",
       "      <td>125457.741358</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014307</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23.979940</td>\n",
       "      <td>128.359539</td>\n",
       "      <td>176924</td>\n",
       "      <td>14756</td>\n",
       "      <td>11308</td>\n",
       "      <td>0.766332</td>\n",
       "      <td>0.063914</td>\n",
       "      <td>0.290995</td>\n",
       "      <td>1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5347</td>\n",
       "      <td>7.400711e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6138.556248</td>\n",
       "      <td>112572.548122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013615</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>22.472079</td>\n",
       "      <td>114.163498</td>\n",
       "      <td>165799</td>\n",
       "      <td>14756</td>\n",
       "      <td>11125</td>\n",
       "      <td>0.753931</td>\n",
       "      <td>0.067099</td>\n",
       "      <td>0.273930</td>\n",
       "      <td>1567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5002</td>\n",
       "      <td>8.251025e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6093.907766</td>\n",
       "      <td>123054.517052</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014295</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>134.787849</td>\n",
       "      <td>195517</td>\n",
       "      <td>14756</td>\n",
       "      <td>11402</td>\n",
       "      <td>0.772703</td>\n",
       "      <td>0.058317</td>\n",
       "      <td>0.296424</td>\n",
       "      <td>1515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5617</td>\n",
       "      <td>8.163608e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>5922.028260</td>\n",
       "      <td>113633.817078</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20.093657</td>\n",
       "      <td>105.391259</td>\n",
       "      <td>148251</td>\n",
       "      <td>14756</td>\n",
       "      <td>10864</td>\n",
       "      <td>0.736243</td>\n",
       "      <td>0.073281</td>\n",
       "      <td>0.259511</td>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5347</td>\n",
       "      <td>7.465687e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6072.637097</td>\n",
       "      <td>116156.818529</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013327</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>24.570480</td>\n",
       "      <td>118.181298</td>\n",
       "      <td>181281</td>\n",
       "      <td>14756</td>\n",
       "      <td>11136</td>\n",
       "      <td>0.754676</td>\n",
       "      <td>0.061429</td>\n",
       "      <td>0.276380</td>\n",
       "      <td>1571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5225</td>\n",
       "      <td>7.974598e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6193.923963</td>\n",
       "      <td>111261.784709</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014021</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23.764028</td>\n",
       "      <td>122.326180</td>\n",
       "      <td>175331</td>\n",
       "      <td>14756</td>\n",
       "      <td>11275</td>\n",
       "      <td>0.764096</td>\n",
       "      <td>0.064307</td>\n",
       "      <td>0.284029</td>\n",
       "      <td>1489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5506</td>\n",
       "      <td>7.352276e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>5993.902684</td>\n",
       "      <td>100397.738820</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20.339387</td>\n",
       "      <td>100.731357</td>\n",
       "      <td>150064</td>\n",
       "      <td>14756</td>\n",
       "      <td>10773</td>\n",
       "      <td>0.730076</td>\n",
       "      <td>0.071789</td>\n",
       "      <td>0.251379</td>\n",
       "      <td>1459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5828</td>\n",
       "      <td>9.669515e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>5932.746476</td>\n",
       "      <td>124574.832999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017060</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19.380049</td>\n",
       "      <td>99.544170</td>\n",
       "      <td>142986</td>\n",
       "      <td>14756</td>\n",
       "      <td>10790</td>\n",
       "      <td>0.731228</td>\n",
       "      <td>0.075462</td>\n",
       "      <td>0.253891</td>\n",
       "      <td>1482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5045</td>\n",
       "      <td>9.971287e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6047.560924</td>\n",
       "      <td>130793.467930</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016316</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>25.759420</td>\n",
       "      <td>136.285705</td>\n",
       "      <td>190053</td>\n",
       "      <td>14756</td>\n",
       "      <td>11430</td>\n",
       "      <td>0.774600</td>\n",
       "      <td>0.060141</td>\n",
       "      <td>0.299738</td>\n",
       "      <td>1577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5372</td>\n",
       "      <td>7.475364e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6008.163256</td>\n",
       "      <td>111541.128333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013918</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>21.780970</td>\n",
       "      <td>110.348360</td>\n",
       "      <td>160700</td>\n",
       "      <td>14756</td>\n",
       "      <td>10973</td>\n",
       "      <td>0.743630</td>\n",
       "      <td>0.068283</td>\n",
       "      <td>0.265695</td>\n",
       "      <td>1542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5371</td>\n",
       "      <td>5.684785e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6128.800352</td>\n",
       "      <td>104965.596338</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011944</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>21.617918</td>\n",
       "      <td>112.591686</td>\n",
       "      <td>159497</td>\n",
       "      <td>14756</td>\n",
       "      <td>11068</td>\n",
       "      <td>0.750068</td>\n",
       "      <td>0.069393</td>\n",
       "      <td>0.269882</td>\n",
       "      <td>1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>5455</td>\n",
       "      <td>7.224269e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6059.107211</td>\n",
       "      <td>115649.473466</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014163</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20.755218</td>\n",
       "      <td>110.990173</td>\n",
       "      <td>153132</td>\n",
       "      <td>14756</td>\n",
       "      <td>11068</td>\n",
       "      <td>0.750068</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.271513</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>5019</td>\n",
       "      <td>1.124990e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>6072.739292</td>\n",
       "      <td>140766.243001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017758</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>26.356194</td>\n",
       "      <td>139.599056</td>\n",
       "      <td>194456</td>\n",
       "      <td>14756</td>\n",
       "      <td>11517</td>\n",
       "      <td>0.780496</td>\n",
       "      <td>0.059227</td>\n",
       "      <td>0.305974</td>\n",
       "      <td>1566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5321</td>\n",
       "      <td>5.719796e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6078.389198</td>\n",
       "      <td>113126.392303</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>22.034427</td>\n",
       "      <td>115.890372</td>\n",
       "      <td>162570</td>\n",
       "      <td>14756</td>\n",
       "      <td>11126</td>\n",
       "      <td>0.753998</td>\n",
       "      <td>0.068438</td>\n",
       "      <td>0.275462</td>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>5217</td>\n",
       "      <td>5.839677e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6196.803741</td>\n",
       "      <td>106548.881286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011255</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23.923014</td>\n",
       "      <td>117.638468</td>\n",
       "      <td>176504</td>\n",
       "      <td>14756</td>\n",
       "      <td>11198</td>\n",
       "      <td>0.758878</td>\n",
       "      <td>0.063443</td>\n",
       "      <td>0.278102</td>\n",
       "      <td>1514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5281</td>\n",
       "      <td>1.016723e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>5989.359040</td>\n",
       "      <td>132094.475067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23.349959</td>\n",
       "      <td>126.645486</td>\n",
       "      <td>172276</td>\n",
       "      <td>14756</td>\n",
       "      <td>11257</td>\n",
       "      <td>0.762876</td>\n",
       "      <td>0.065343</td>\n",
       "      <td>0.287634</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>5444</td>\n",
       "      <td>8.496872e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>5957.906275</td>\n",
       "      <td>123534.533794</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015785</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>21.219707</td>\n",
       "      <td>110.784948</td>\n",
       "      <td>156559</td>\n",
       "      <td>14756</td>\n",
       "      <td>11002</td>\n",
       "      <td>0.745595</td>\n",
       "      <td>0.070274</td>\n",
       "      <td>0.269025</td>\n",
       "      <td>1468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>5612</td>\n",
       "      <td>7.805011e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>5868.893399</td>\n",
       "      <td>126707.020626</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015166</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20.615343</td>\n",
       "      <td>106.250638</td>\n",
       "      <td>152100</td>\n",
       "      <td>14756</td>\n",
       "      <td>10869</td>\n",
       "      <td>0.736582</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.261245</td>\n",
       "      <td>1513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>4872</td>\n",
       "      <td>6.383416e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6128.803538</td>\n",
       "      <td>118800.595342</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>26.747221</td>\n",
       "      <td>141.169315</td>\n",
       "      <td>197341</td>\n",
       "      <td>14756</td>\n",
       "      <td>11512</td>\n",
       "      <td>0.780157</td>\n",
       "      <td>0.058336</td>\n",
       "      <td>0.304214</td>\n",
       "      <td>1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>5136</td>\n",
       "      <td>5.978008e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6179.616969</td>\n",
       "      <td>113091.957780</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011948</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23.847384</td>\n",
       "      <td>124.306685</td>\n",
       "      <td>175946</td>\n",
       "      <td>14756</td>\n",
       "      <td>11302</td>\n",
       "      <td>0.765926</td>\n",
       "      <td>0.064236</td>\n",
       "      <td>0.286499</td>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>5289</td>\n",
       "      <td>5.383731e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6122.497493</td>\n",
       "      <td>98686.766224</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23.585796</td>\n",
       "      <td>111.999554</td>\n",
       "      <td>174016</td>\n",
       "      <td>14756</td>\n",
       "      <td>11036</td>\n",
       "      <td>0.747899</td>\n",
       "      <td>0.063419</td>\n",
       "      <td>0.267564</td>\n",
       "      <td>1519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>5678</td>\n",
       "      <td>7.580633e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>5930.726484</td>\n",
       "      <td>108803.615985</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014207</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>21.967335</td>\n",
       "      <td>109.615776</td>\n",
       "      <td>162075</td>\n",
       "      <td>14756</td>\n",
       "      <td>10893</td>\n",
       "      <td>0.738208</td>\n",
       "      <td>0.067210</td>\n",
       "      <td>0.261409</td>\n",
       "      <td>1550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5378</td>\n",
       "      <td>1.054373e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>6077.905665</td>\n",
       "      <td>118538.023854</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016759</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>22.477365</td>\n",
       "      <td>110.255375</td>\n",
       "      <td>165838</td>\n",
       "      <td>14756</td>\n",
       "      <td>11041</td>\n",
       "      <td>0.748238</td>\n",
       "      <td>0.066577</td>\n",
       "      <td>0.269015</td>\n",
       "      <td>1519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5053</td>\n",
       "      <td>5.063331e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6197.763418</td>\n",
       "      <td>105575.998995</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010143</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>25.600840</td>\n",
       "      <td>121.910823</td>\n",
       "      <td>188883</td>\n",
       "      <td>14756</td>\n",
       "      <td>11243</td>\n",
       "      <td>0.761927</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.281598</td>\n",
       "      <td>1583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5355</td>\n",
       "      <td>5.371668e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>6106.049065</td>\n",
       "      <td>104626.043976</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011964</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>21.258336</td>\n",
       "      <td>108.945772</td>\n",
       "      <td>156844</td>\n",
       "      <td>14756</td>\n",
       "      <td>10999</td>\n",
       "      <td>0.745392</td>\n",
       "      <td>0.070127</td>\n",
       "      <td>0.265385</td>\n",
       "      <td>1582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0             1   2            3              4   5         6   \\\n",
       "0    5784  1.919681e+07   0  4793.972825  240661.980998   0  0.031190   \n",
       "1    6794  3.178820e+07   0  5218.149024  311968.162671   0  0.052891   \n",
       "2    3145  3.008115e+07   0  6449.089184  271046.371279   0  0.022461   \n",
       "3    7103  2.819635e+07   0  4711.488411  324698.997066   0  0.063424   \n",
       "4    5103  2.206385e+07   0  4751.740241  214261.707832   0  0.025997   \n",
       "5    6709  3.081925e+07   0  4355.848333  274532.883561   0  0.063441   \n",
       "6    9373  4.384667e+07   0  6580.887436  511810.575646   0  0.106310   \n",
       "7    7470  2.090158e+07   0  4203.179385  208935.551557   0  0.051416   \n",
       "8    8761  5.882291e+07   0  5273.566481  493581.508209   0  0.121513   \n",
       "9    3652  2.520365e+07   0  5984.770670  344248.997834   0  0.079699   \n",
       "10   5217  3.207252e+07   0  5411.318786  315824.945159   0  0.065111   \n",
       "11   6070  4.826322e+07   0  5541.303470  416815.106761   0  0.087928   \n",
       "12   4676  8.059084e+06   0  4944.723367   94101.990454   0  0.008376   \n",
       "13   3107  1.970367e+07   0  5390.699648  256693.737679   0  0.029068   \n",
       "14   5250  2.364352e+07   0  5621.956425  309248.862247   0  0.044284   \n",
       "15   6056  3.913562e+07   0  5685.302657  360956.476087   0  0.081263   \n",
       "16   8092  2.063759e+07   0  3938.772160  209749.675163   0  0.061286   \n",
       "17   3078  2.678981e+07   0  5724.722960  341169.802640   0  0.086848   \n",
       "18   7440  3.990279e+07   0  4246.773719  331077.317437   0  0.074181   \n",
       "19   7955  2.897846e+07   0  5095.622052  328978.916090   0  0.069540   \n",
       "20   6434  2.895810e+07   0  6088.712930  343894.919309   0  0.046534   \n",
       "21   4800  2.231146e+07   0  5085.328815  237447.362271   0  0.040080   \n",
       "22   6105  2.314741e+07   0  5139.665424  266173.380854   0  0.048682   \n",
       "23   5752  3.143332e+07   0  5994.125644  346376.935818   0  0.065157   \n",
       "24   9251  4.503658e+07   0  5621.641027  416510.079161   0  0.109054   \n",
       "25   6430  3.447845e+07   0  6037.910613  404218.838125   0  0.059055   \n",
       "26   3865  3.907966e+06   0  5371.511182   71638.215867   0  0.004825   \n",
       "27   6704  3.533555e+07   0  4683.371849  312530.480583   0  0.068542   \n",
       "28   4450  2.141574e+07   0  5571.240445  241979.188406   0  0.032462   \n",
       "29   6100  2.572861e+07   0  4728.525617  260641.138066   0  0.046892   \n",
       "..    ...           ...  ..          ...            ...  ..       ...   \n",
       "86   2909  1.618914e+07   0  6215.537815  269015.077559   0  0.034481   \n",
       "87   5446  4.940079e+07   0  5699.822581  410522.644652   0  0.054014   \n",
       "88   5194  5.372219e+06   0  6124.862022  108304.975097   0  0.011246   \n",
       "89   5552  1.155857e+07   0  5856.485633  136609.612447   0  0.019519   \n",
       "90   5284  1.143807e+07   0  6060.939076  145334.394664   0  0.017926   \n",
       "91   5135  7.660071e+06   0  6014.238208  125457.741358   0  0.014307   \n",
       "92   5347  7.400711e+06   0  6138.556248  112572.548122   0  0.013615   \n",
       "93   5002  8.251025e+06   0  6093.907766  123054.517052   0  0.014295   \n",
       "94   5617  8.163608e+06   0  5922.028260  113633.817078   0  0.015667   \n",
       "95   5347  7.465687e+06   0  6072.637097  116156.818529   0  0.013327   \n",
       "96   5225  7.974598e+06   0  6193.923963  111261.784709   0  0.014021   \n",
       "97   5506  7.352276e+06   0  5993.902684  100397.738820   0  0.013438   \n",
       "98   5828  9.669515e+06   0  5932.746476  124574.832999   0  0.017060   \n",
       "99   5045  9.971287e+06   0  6047.560924  130793.467930   0  0.016316   \n",
       "100  5372  7.475364e+06   0  6008.163256  111541.128333   0  0.013918   \n",
       "101  5371  5.684785e+06   0  6128.800352  104965.596338   0  0.011944   \n",
       "102  5455  7.224269e+06   0  6059.107211  115649.473466   0  0.014163   \n",
       "103  5019  1.124990e+07   0  6072.739292  140766.243001   0  0.017758   \n",
       "104  5321  5.719796e+06   0  6078.389198  113126.392303   0  0.012073   \n",
       "105  5217  5.839677e+06   0  6196.803741  106548.881286   0  0.011255   \n",
       "106  5281  1.016723e+07   0  5989.359040  132094.475067   0  0.017094   \n",
       "107  5444  8.496872e+06   0  5957.906275  123534.533794   0  0.015785   \n",
       "108  5612  7.805011e+06   0  5868.893399  126707.020626   0  0.015166   \n",
       "109  4872  6.383416e+06   0  6128.803538  118800.595342   0  0.012422   \n",
       "110  5136  5.978008e+06   0  6179.616969  113091.957780   0  0.011948   \n",
       "111  5289  5.383731e+06   0  6122.497493   98686.766224   0  0.010904   \n",
       "112  5678  7.580633e+06   0  5930.726484  108803.615985   0  0.014207   \n",
       "113  5378  1.054373e+07   0  6077.905665  118538.023854   0  0.016759   \n",
       "114  5053  5.063331e+06   0  6197.763418  105575.998995   0  0.010143   \n",
       "115  5355  5.371668e+06   0  6106.049065  104626.043976   0  0.011964   \n",
       "\n",
       "           7         8         9   ...   22          23          24       25  \\\n",
       "0    0.000012  0.000068  0.000481  ...    0   30.865140  193.585539   227723   \n",
       "1    0.000012  0.000068  0.000661  ...    0   23.456899  194.776024   173065   \n",
       "2    0.000011  0.000068  0.000252  ...    0  178.899837  463.849655  1319923   \n",
       "3    0.000012  0.000068  0.000809  ...    0   14.067362  149.268327   103789   \n",
       "4    0.000013  0.000068  0.000349  ...    0   47.044728  208.237730   347096   \n",
       "5    0.000013  0.000068  0.000724  ...    0   13.148008  133.300700    97006   \n",
       "6    0.000011  0.000068  0.001298  ...    0   10.064381  173.156916    74255   \n",
       "7    0.000014  0.000068  0.000680  ...    0   12.307943  125.001291    90808   \n",
       "8    0.000012  0.000068  0.001141  ...    0    9.539848  133.331617    70385   \n",
       "9    0.000011  0.000068  0.001264  ...    0   10.989157  213.964344    81078   \n",
       "10   0.000012  0.000068  0.000872  ...    0   16.104906  200.336599   118822   \n",
       "11   0.000011  0.000068  0.000950  ...    0   13.376931  170.081898    98695   \n",
       "12   0.000013  0.000068  0.000199  ...    0   76.999458  237.035602   568102   \n",
       "13   0.000012  0.000068  0.000465  ...    0   42.116698  240.623195   310737   \n",
       "14   0.000011  0.000068  0.000677  ...    0   25.336677  219.535780   186934   \n",
       "15   0.000011  0.000068  0.001043  ...    0   13.258607  204.414478    97822   \n",
       "16   0.000014  0.000068  0.000756  ...    0    8.783410   98.046945    64804   \n",
       "17   0.000011  0.000068  0.001313  ...    0    9.859718  199.706977    72745   \n",
       "18   0.000013  0.000068  0.000712  ...    0   12.451477  113.172913    91867   \n",
       "19   0.000012  0.000068  0.000927  ...    0   13.391027  171.046967    98799   \n",
       "20   0.000011  0.000068  0.000657  ...    0   29.243969  225.938628   215762   \n",
       "21   0.000012  0.000068  0.000614  ...    0   26.309027  225.905555   194108   \n",
       "22   0.000012  0.000068  0.000742  ...    0   19.636758  206.983531   144880   \n",
       "23   0.000011  0.000068  0.000919  ...    0   16.975197  216.325576   125243   \n",
       "24   0.000011  0.000068  0.001257  ...    0    9.155191  166.639584    67547   \n",
       "25   0.000011  0.000068  0.000770  ...    0   21.420575  199.120938   158041   \n",
       "26   0.000012  0.000068  0.000179  ...    0  121.835728  346.688031   898904   \n",
       "27   0.000012  0.000068  0.000779  ...    0   14.412442  152.452333   106335   \n",
       "28   0.000011  0.000068  0.000521  ...    0   39.203985  274.203368   289247   \n",
       "29   0.000012  0.000068  0.000630  ...    0   21.135538  182.063113   155938   \n",
       "..        ...       ...       ...  ...   ..         ...         ...      ...   \n",
       "86   0.000011  0.000068  0.000687  ...    0   30.705340  288.000768   226544   \n",
       "87   0.000012  0.000068  0.000532  ...    0   23.879642  148.624134   176184   \n",
       "88   0.000013  0.000068  0.000324  ...    0   23.615885  119.874611   174238   \n",
       "89   0.000013  0.000068  0.000364  ...    0   20.619545  114.972961   152131   \n",
       "90   0.000013  0.000068  0.000342  ...    0   24.962998  129.115220   184177   \n",
       "91   0.000013  0.000068  0.000347  ...    0   23.979940  128.359539   176924   \n",
       "92   0.000013  0.000068  0.000325  ...    0   22.472079  114.163498   165799   \n",
       "93   0.000013  0.000068  0.000329  ...    0   26.500000  134.787849   195517   \n",
       "94   0.000013  0.000068  0.000337  ...    0   20.093657  105.391259   148251   \n",
       "95   0.000013  0.000068  0.000312  ...    0   24.570480  118.181298   181281   \n",
       "96   0.000013  0.000068  0.000328  ...    0   23.764028  122.326180   175331   \n",
       "97   0.000013  0.000068  0.000312  ...    0   20.339387  100.731357   150064   \n",
       "98   0.000013  0.000068  0.000334  ...    0   19.380049   99.544170   142986   \n",
       "99   0.000013  0.000068  0.000342  ...    0   25.759420  136.285705   190053   \n",
       "100  0.000013  0.000068  0.000324  ...    0   21.780970  110.348360   160700   \n",
       "101  0.000013  0.000068  0.000329  ...    0   21.617918  112.591686   159497   \n",
       "102  0.000013  0.000068  0.000347  ...    0   20.755218  110.990173   153132   \n",
       "103  0.000012  0.000068  0.000348  ...    0   26.356194  139.599056   194456   \n",
       "104  0.000013  0.000068  0.000337  ...    0   22.034427  115.890372   162570   \n",
       "105  0.000013  0.000068  0.000311  ...    0   23.923014  117.638468   176504   \n",
       "106  0.000013  0.000068  0.000351  ...    0   23.349959  126.645486   172276   \n",
       "107  0.000013  0.000068  0.000339  ...    0   21.219707  110.784948   156559   \n",
       "108  0.000013  0.000068  0.000336  ...    0   20.615343  106.250638   152100   \n",
       "109  0.000013  0.000068  0.000339  ...    0   26.747221  141.169315   197341   \n",
       "110  0.000013  0.000068  0.000334  ...    0   23.847384  124.306685   175946   \n",
       "111  0.000013  0.000068  0.000301  ...    0   23.585796  111.999554   174016   \n",
       "112  0.000013  0.000068  0.000317  ...    0   21.967335  109.615776   162075   \n",
       "113  0.000013  0.000068  0.000317  ...    0   22.477365  110.255375   165838   \n",
       "114  0.000013  0.000068  0.000303  ...    0   25.600840  121.910823   188883   \n",
       "115  0.000013  0.000068  0.000326  ...    0   21.258336  108.945772   156844   \n",
       "\n",
       "        26     27        28        29        30    31  \n",
       "0    14756  11649  0.789442  0.051154  0.348444  1733  \n",
       "1    14756  12369  0.838235  0.071470  0.396730  1451  \n",
       "2    14756  13866  0.939686  0.010505  0.505752  3366  \n",
       "3    14756  11618  0.787341  0.111939  0.346997  1053  \n",
       "4    14756  11432  0.774736  0.032936  0.332817  2112  \n",
       "5    14756  10861  0.736040  0.111962  0.297630   995  \n",
       "6    14756  13935  0.944362  0.187664  0.499722   836  \n",
       "7    14756  10302  0.698157  0.113448  0.260771   940  \n",
       "8    14756  12463  0.844606  0.177069  0.401404   909  \n",
       "9    14756  13279  0.899905  0.163781  0.456437   514  \n",
       "10   14756  12609  0.854500  0.106117  0.412319   807  \n",
       "11   14756  12777  0.865885  0.129459  0.422868   811  \n",
       "12   14756  11024  0.747086  0.019405  0.297434  2745  \n",
       "13   14756  12509  0.847723  0.040256  0.405311  2239  \n",
       "14   14756  12862  0.871645  0.068805  0.429259  1296  \n",
       "15   14756  12949  0.877541  0.132373  0.434797   513  \n",
       "16   14756   9704  0.657631  0.149744  0.226128   848  \n",
       "17   14756  12969  0.878897  0.178280  0.434931   440  \n",
       "18   14756  10663  0.722621  0.116070  0.285318  1043  \n",
       "19   14756  12197  0.826579  0.123453  0.384803   877  \n",
       "20   14756  13408  0.908647  0.062143  0.466542  1900  \n",
       "21   14756  12148  0.823258  0.062584  0.382035  1020  \n",
       "22   14756  12224  0.828409  0.084373  0.386618   917  \n",
       "23   14756  13301  0.901396  0.106202  0.458919   924  \n",
       "24   14756  12872  0.872323  0.190564  0.428968   538  \n",
       "25   14756  13350  0.904717  0.084472  0.461498  1041  \n",
       "26   14756  11771  0.797709  0.013095  0.346845  3224  \n",
       "27   14756  11532  0.781513  0.108450  0.340968  1011  \n",
       "28   14756  12785  0.866427  0.044201  0.424914  1541  \n",
       "29   14756  11601  0.786189  0.074395  0.345848  1180  \n",
       "..     ...    ...       ...       ...       ...   ...  \n",
       "86   14756  13526  0.916644  0.059706  0.474667  1067  \n",
       "87   14756  12430  0.842369  0.070551  0.389794  1522  \n",
       "88   14756  11193  0.758539  0.064240  0.279458  1512  \n",
       "89   14756  11041  0.748238  0.072576  0.274417  1517  \n",
       "90   14756  11379  0.771144  0.061783  0.295389  1503  \n",
       "91   14756  11308  0.766332  0.063914  0.290995  1560  \n",
       "92   14756  11125  0.753931  0.067099  0.273930  1567  \n",
       "93   14756  11402  0.772703  0.058317  0.296424  1515  \n",
       "94   14756  10864  0.736243  0.073281  0.259511  1477  \n",
       "95   14756  11136  0.754676  0.061429  0.276380  1571  \n",
       "96   14756  11275  0.764096  0.064307  0.284029  1489  \n",
       "97   14756  10773  0.730076  0.071789  0.251379  1459  \n",
       "98   14756  10790  0.731228  0.075462  0.253891  1482  \n",
       "99   14756  11430  0.774600  0.060141  0.299738  1577  \n",
       "100  14756  10973  0.743630  0.068283  0.265695  1542  \n",
       "101  14756  11068  0.750068  0.069393  0.269882  1437  \n",
       "102  14756  11068  0.750068  0.072278  0.271513  1531  \n",
       "103  14756  11517  0.780496  0.059227  0.305974  1566  \n",
       "104  14756  11126  0.753998  0.068438  0.275462  1539  \n",
       "105  14756  11198  0.758878  0.063443  0.278102  1514  \n",
       "106  14756  11257  0.762876  0.065343  0.287634  1488  \n",
       "107  14756  11002  0.745595  0.070274  0.269025  1468  \n",
       "108  14756  10869  0.736582  0.071460  0.261245  1513  \n",
       "109  14756  11512  0.780157  0.058336  0.304214  1540  \n",
       "110  14756  11302  0.765926  0.064236  0.286499  1491  \n",
       "111  14756  11036  0.747899  0.063419  0.267564  1519  \n",
       "112  14756  10893  0.738208  0.067210  0.261409  1550  \n",
       "113  14756  11041  0.748238  0.066577  0.269015  1519  \n",
       "114  14756  11243  0.761927  0.059524  0.281598  1583  \n",
       "115  14756  10999  0.745392  0.070127  0.265385  1582  \n",
       "\n",
       "[116 rows x 32 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parenclitics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Betweenness', 'Pagerank', 'Closeness', 'Eigenvector centrality', 'Degrees']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parenclitic_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "parenclitic_names = parenclitic_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['Degrees', 'Min degrees', 'Max degrees', 'Mean degrees', 'Std degrees', 'Zeros degrees', 'Efficiency', 'Betweenness', 'Min betweenness', 'Max betweenness', 'Mean betweenness', 'Std betweenness', 'Zeros betweenness', 'Closeness', 'Min closeness', 'Max closeness', 'Mean closeness', 'Std closeness', 'Zeros closeness', 'Pagerank', 'Min pagerank', 'Max pagerank', 'Mean pagerank', 'Std pagerank', 'Zeros pagerank', 'Eigenvalues', 'Eigenvector centrality', 'Min eigenvector centrality', 'Max eigenvector centrality', 'Mean eigenvector centrality', 'Std eigenvector centrality', 'Zeros eigenvector centrality', 'Number of edges', 'Number of nodes', 'Max component size', 'Max component size norm nodes', 'Max component size norm edges', 'Eigenvalues intervals', 'Eigenvalues intervals normalized', 'IPR', 'Max IPR', 'Mean IPR', 'Weights', 'Sum weights', 'Min weights', 'Max weights', 'Mean weights', 'Std weights', 'Zeros weights', 'Community edge betweenness: optimal count', 'Component sizes', 'Robustness'])\n"
     ]
    }
   ],
   "source": [
    "print(parenclitic_names.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centrality sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 3\n",
    "degrees_d = parenclitics[4][0 + i]\n",
    "degrees_s = parenclitics[4][29 + i]\n",
    "degrees_m = parenclitics[4][29 * 2 + i]\n",
    "ids = np.argsort(degrees_d)\n",
    "degrees_d = degrees_d[ids]\n",
    "degrees_s = degrees_s[ids]\n",
    "degrees_m = degrees_m[ids]\n",
    "plt.plot(degrees_m)\n",
    "plt.plot(degrees_s)\n",
    "plt.plot(degrees_d)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
